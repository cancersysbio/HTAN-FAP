{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4385ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyranges as pr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db07a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory where unfiltered mutation data are stored\n",
    "# if using the zenodo data, this should point to the location of the base zenodo directory \n",
    "data_dir = \"\"\n",
    "\n",
    "# filtered mafs (filename suffix \"_filtered.maf\") must be present in input_dir\n",
    "input_dir = data_dir + \"ppVAF_temp/\"\n",
    "save_dir = data_dir + \"ppVAF_temp/\"\n",
    "\n",
    "# names of datasets which you want to process- should match maf and copy number file names.\n",
    "# external datasets (\"PUTH\" and \"SCORT\") not included with our repo- you will have to generate these yourself\n",
    "\n",
    "# if you are processing the HTAN WES cohort, the WGS calls must also be present under name \"HTAN_WGS\". the WGS calls \n",
    "# are used for the HTAN WES ppVAF calculations.\n",
    "maf_names = ['HTAN_WGS', \"HTAN_WES\", \"PUTH\", \"SCORT\"]\n",
    "\n",
    "# directory containing the .tsv FACETS CN merged and filtered files for each dataset. Default repo location given.\n",
    "CN_dir = \"../../data/copy_number/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b59c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/software/user/open/py-jupyter/1.0.0_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (87,88,90) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/tmp/ipykernel_10544/1740092743.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  only_sample[\"tcn\"] = [mutid_to_tcn[only_sample.iloc[i][\"Mut_ID\"]] if only_sample.iloc[i][\"Chromosome\"] != \"chrY\" else 1 for i in range(len(only_sample))]\n",
      "/tmp/ipykernel_10544/1740092743.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  only_sample[\"lcn\"] = [mutid_to_lcn[only_sample.iloc[i][\"Mut_ID\"]] if only_sample.iloc[i][\"Chromosome\"] != \"chrY\" else 0 for i in range(len(only_sample))]\n"
     ]
    }
   ],
   "source": [
    "ranges_cols = [\"Chromosome\", \"Start_Position\", \"End_Position\", \"Strand\", \"Mut_ID\"]\n",
    "CN_cols = [\"chrom\", \"loc_start\", \"loc_end\", \"tcn_em\", \"lcn_em\"]\n",
    "\n",
    "CN_mafs = []\n",
    "for i,save_name in enumerate(maf_names):\n",
    "    maf = pd.read_csv(input_dir+save_name+\"_filtered.maf\", sep=\"\\t\")\n",
    "    CNs = pd.read_csv(CN_dir+save_name+\"_CN_filtered_merged.tsv\", sep=\"\\t\")\n",
    "    if save_name == \"HTAN_WES\":\n",
    "        WGS_CNs = pd.read_csv(CN_dir+\"HTAN_WGS_CN_filtered_merged.tsv\", sep=\"\\t\")\n",
    "        WGS_samples = list(set(WGS_CNs[\"sample_id\"]))\n",
    "    maf_samples = list(set(maf[\"Tumor_Sample_Barcode\"]))\n",
    "    to_concat = []\n",
    "    for sample in maf_samples:\n",
    "        only_sample = maf[maf[\"Tumor_Sample_Barcode\"] == sample]\n",
    "        sample_ranges = only_sample[ranges_cols].rename(columns={\"Start_Position\":\"Start\", \"End_Position\":\"End\"})\n",
    "        sample_ranges = pr.PyRanges(sample_ranges)\n",
    "        if sample not in list(set(CNs[\"sample_id\"])):\n",
    "            print(sample, \"not found in copy number\")\n",
    "            continue\n",
    "        \n",
    "        if save_name == \"HTAN_WES\" and sample in WGS_samples:\n",
    "            CN_sample = WGS_CNs[WGS_CNs[\"sample_id\"]==sample]\n",
    "        else:\n",
    "            CN_sample = CNs[CNs[\"sample_id\"]==sample]\n",
    "        \n",
    "        CN_ranges = CN_sample[CN_cols].rename(columns={\"loc_start\":\"Start\", \"loc_end\":\"End\", \"chrom\":\"Chromosome\"})\n",
    "        CN_ranges[\"Strand\"] = \"+\"\n",
    "        CN_ranges = pr.PyRanges(CN_ranges)\n",
    "        \n",
    "        CN_intersect = sample_ranges.join(CN_ranges).df\n",
    "        \n",
    "        duplicates = CN_intersect.value_counts(\"Mut_ID\")\n",
    "        duplicates = duplicates[duplicates > 1]\n",
    "\n",
    "        if len(duplicates) > 0:\n",
    "            CN_intersect[\"start_intersect\"] = np.maximum(CN_intersect[\"Start\"], CN_intersect[\"Start_b\"])\n",
    "            CN_intersect[\"end_intersect\"] = np.minimum(CN_intersect[\"End\"], CN_intersect[\"End_b\"])\n",
    "            CN_intersect[\"len_intersect\"] = CN_intersect[\"end_intersect\"] - CN_intersect[\"start_intersect\"]\n",
    "            deduplicated = []\n",
    "            for mut in duplicates.index:\n",
    "                both_listings = CN_intersect[CN_intersect[\"Mut_ID\"]==mut]\n",
    "                to_add = pd.DataFrame(both_listings.iloc[0]).transpose()\n",
    "                longest_segment = both_listings.sort_values(\"len_intersect\", ascending=False).iloc[0]\n",
    "                to_add[\"tcn_em\"] = longest_segment[\"tcn_em\"]\n",
    "                to_add[\"lcn_em\"] = longest_segment[\"lcn_em\"]\n",
    "                deduplicated.append(to_add)\n",
    "\n",
    "            deduplicated = pd.concat(deduplicated)\n",
    "            CN_intersect = CN_intersect[~np.isin(CN_intersect[\"Mut_ID\"], duplicates.index)]\n",
    "            CN_intersect = pd.concat([CN_intersect, deduplicated])\n",
    "            \n",
    "            print(\"Resolved breakpoint within mutation\")\n",
    "        mutid_to_tcn = dict(zip(CN_intersect[\"Mut_ID\"], CN_intersect[\"tcn_em\"]))\n",
    "        mutid_to_lcn = dict(zip(CN_intersect[\"Mut_ID\"], CN_intersect[\"lcn_em\"]))\n",
    "        only_sample[\"tcn\"] = [mutid_to_tcn[only_sample.iloc[i][\"Mut_ID\"]] if only_sample.iloc[i][\"Chromosome\"] != \"chrY\" else 1 for i in range(len(only_sample))]\n",
    "        only_sample[\"lcn\"] = [mutid_to_lcn[only_sample.iloc[i][\"Mut_ID\"]] if only_sample.iloc[i][\"Chromosome\"] != \"chrY\" else 0 for i in range(len(only_sample))]\n",
    "        to_concat.append(only_sample)\n",
    "    CN_mafs.append(pd.concat(to_concat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3983d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,save_name in enumerate(maf_names):\n",
    "    to_save = CN_mafs[i]\n",
    "    to_save = to_save[to_save[\"tcn\"] != 0]\n",
    "    to_save.to_csv(save_dir+save_name+\"_filtered_CNs.maf\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be091595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_sherlock",
   "language": "python",
   "name": "py39_sherlock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
