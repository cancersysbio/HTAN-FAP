{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b109e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS NOTEBOOK TAKES THE ppVAF POSTERIORS AND FILTERS AND ANNOTATES THE WGS AND WES MAFS WITH A COLUMN WITH ppVAF POINT ESTIMATES\n",
    "# ALSO OUTPUTS A .csv file (clonal_noshared_WES_WGS_polycalls.csv) CONTAINING THE EXPECTED CLONAL SNV COUNTS AND POLYCLONAL CALLS\n",
    "# It will probably require a lot of memory to run (>100GB)\n",
    "\n",
    "all_patients_to_process = [\"A001\", \"A002\", \"A015\", \"A014\", \"F001\", \"G001\"]\n",
    "\n",
    "# directory containing the .npy unnormalized ppVAF probabilities for WES and WGS data and per-patient maf files\n",
    "# calculated by calculate_ppVAF_posteriors.py, with filenames that are of the form [[PATIENT]][[WES_npy_postfix]]\n",
    "# and [[PATIENT]][[WES_maf_postfix]] for the WES data, respectively\n",
    "input_dir = \"/path/to/input/root/dir/\"\n",
    "\n",
    "WES_npy_postfix = \"_ppVAFgivenPurity_noprior_WES.npy\"\n",
    "WES_maf_postfix = \"_muts_WES.maf\"\n",
    "WGS_npy_postfix = \"_ppVAFgivenPurity_noprior_WGS.npy\"\n",
    "WGS_maf_postfix = \"_muts_WGS.maf\"\n",
    "\n",
    "# directory to save the new mafs with ppVAFs in a new \"purity_ccf\" column\n",
    "# must mirror structure of the zenodo directory (have subdirectories \"wes\", \"wgs\", and \"wgs_wes\" in which data will be saved)\n",
    "# output files are inputs to most downstream plotting scripts and are provided in the zenodo distribution\n",
    "output_dir = \"/path/to/output/root/dir/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_dir = \"../../data/scATACseq_annotations/\"\n",
    "purity_dict = pickle.load(open(annot_dir+\"scATAC_purities.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81597774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS\n",
    "\n",
    "def purity_dist_normalize(prob_mat, maf, purity_dict):\n",
    "    all_stages = list(set(maf[\"Stage\"]))\n",
    "    for stage in all_stages:\n",
    "        if stage not in purity_dict:\n",
    "            raise AssertionError(\"invalid stage\")\n",
    "        has_stage = np.nonzero((maf[\"Stage\"] == stage).tolist())[0]\n",
    "        prob_mat[:, :, has_stage] = np.multiply(prob_mat[:, :, has_stage], purity_dict[stage].reshape((-1, 1, 1)))\n",
    "    prob_mat = np.divide(prob_mat, np.sum(prob_mat, axis=(0,1)).reshape(1, 1, -1))\n",
    "    return prob_mat\n",
    "\n",
    "def get_ccfs_clonality_many(probs):\n",
    "    num_ccf_grid = np.shape(probs)[0]\n",
    "    \n",
    "    ccfs = np.argmax(probs, axis=0)\n",
    "    ccf_half_max = probs > (np.max(probs, axis=0).reshape((1, -1)) / 2)\n",
    "    ccf_half_max = np.where(ccf_half_max==0, np.nan, np.arange(num_ccf_grid).reshape(-1,1))\n",
    "    \n",
    "    ccf_lower = np.maximum(np.nanmin(ccf_half_max, axis=0) - 1, 1) # closest ccf value before half-max range (within 0-1 range)\n",
    "    ccf_upper = np.minimum(np.nanmax(ccf_half_max, axis=0) + 1, num_ccf_grid) # closest ccf value after half-max range (within 0-1 range)\n",
    "\n",
    "    ccf_lower = ccf_lower / num_ccf_grid\n",
    "    ccf_upper = ccf_upper / num_ccf_grid\n",
    "    \n",
    "    ccfs = ccfs/num_ccf_grid\n",
    "    \n",
    "    clonality = np.array([\"SUBCLONAL-\"] * np.shape(probs)[1])\n",
    "    clonal_condition = np.logical_and(ccfs >= .9, np.sum(probs[850:, :], axis=0)>=0.75)\n",
    "    clonality = np.where(clonal_condition, \"CLONAL+\", clonality)\n",
    "    clonal_condition = np.logical_and(ccf_lower < .5, np.sum(probs[:500, :], axis=0)>=0.75)\n",
    "    clonality = np.where(clonal_condition, \"SUBCLONAL+\", clonality)\n",
    "    clonal_condition = np.logical_and(ccfs >= .9, np.logical_or(np.sum(probs[850:, :], axis=0)>=0.5, ccf_lower>=0.5))\n",
    "    clonality = np.where(clonal_condition, \"CLONAL-\", clonality)\n",
    "    return (ccfs, clonality, ccf_lower, ccf_upper)\n",
    "\n",
    "def get_CCF_MAP(prob_mat, maf, ccf_col=\"purity_ccf\", clonal_col=\"purity_clonal\", bounds_prefix=\"purity\"):\n",
    "    #adds new columns to maf df with best ccf estimate marginalized over purity distribution\n",
    "    marginalized = np.sum(prob_mat, axis=0)\n",
    "    CCFs, clonality, lower, upper = get_ccfs_clonality_many(marginalized)\n",
    "    maf[ccf_col] = CCFs\n",
    "    maf[clonal_col] = clonality\n",
    "    maf[bounds_prefix+\"_lower\"] = lower\n",
    "    maf[bounds_prefix+\"_upper\"] = upper\n",
    "    return marginalized\n",
    "\n",
    "def expected_count_clonal(prob_mat, maf, clonal_threshold=0.95, filter_maf=None):\n",
    "    num_ccf_grid = np.shape(prob_mat)[1]\n",
    "    idx_threshold = int(clonal_threshold*num_ccf_grid)\n",
    "    \n",
    "    probs_clonal = np.sum(prob_mat[:, idx_threshold:, :], axis=1)\n",
    "    \n",
    "    all_samples = list(set(maf[\"Tumor_Sample_Barcode\"]))\n",
    "    to_return = []\n",
    "    CI_clonal = []\n",
    "    for sample in all_samples:\n",
    "        if filter_maf is not None:\n",
    "            is_sample = list(set(np.nonzero((maf[\"Tumor_Sample_Barcode\"] == sample).tolist())[0]).intersection(set(filter_maf)))\n",
    "        else:\n",
    "            is_sample = np.nonzero((maf[\"Tumor_Sample_Barcode\"] == sample).tolist())[0]\n",
    "        sample_probs = probs_clonal[:, is_sample]\n",
    "        to_return.append(np.nansum(sample_probs))\n",
    "        CI_clonal.append(np.nansum(maf.iloc[is_sample][\"purity_upper\"]==1))\n",
    "    return pd.DataFrame({\"sample\":all_samples, \"exp_clonal\":to_return, \"CI_clonal\":CI_clonal})\n",
    "\n",
    "def add_ccfs_count_clonal(prob_mat, maf, purity_dict):\n",
    "    maf_save = None\n",
    "    clonal = None\n",
    "    all_marg = np.zeros((np.shape(prob_mat)[2], np.shape(prob_mat)[1]))\n",
    "    start_idx = 0\n",
    "    for sample in list(set(maf[\"Tumor_Sample_Barcode\"])):\n",
    "        is_sample = np.nonzero((maf[\"Tumor_Sample_Barcode\"] == sample).tolist())[0]\n",
    "        new_maf = maf.iloc[is_sample]\n",
    "        new_mat = prob_mat[:, :, is_sample]\n",
    "        n_muts = len(new_maf)\n",
    "        new_mat = purity_dist_normalize(new_mat, new_maf, purity_dict)\n",
    "        marg = get_CCF_MAP(new_mat, new_maf)\n",
    "        all_marg[start_idx:start_idx+n_muts,:] = np.transpose(marg)\n",
    "        start_idx += n_muts\n",
    "        \n",
    "        filter_maf = np.logical_and(np.isin(new_maf[\"Reference_Allele\"], [\"A\", \"T\", \"C\", \"G\"]), np.isin(new_maf[\"Tumor_Seq_Allele2\"], [\"A\", \"T\", \"C\", \"G\"]))\n",
    "        filter_maf = np.logical_and(filter_maf, new_maf[\"t_depth\"] >= 10)\n",
    "        filter_maf = np.logical_and(filter_maf, new_maf[\"t_alt_count\"] >= 2)\n",
    "        filter_maf = np.logical_and(filter_maf, new_maf[\"vaf\"] >= 0.01)\n",
    "        clonal_add = expected_count_clonal(new_mat, new_maf, filter_maf=np.nonzero((filter_maf).tolist())[0])\n",
    "        clonal_add[\"patient\"] = patient\n",
    "\n",
    "        if clonal is None:\n",
    "            clonal = clonal_add\n",
    "        else:\n",
    "            clonal = pd.concat([clonal, clonal_add])\n",
    "        if maf_save is None:\n",
    "            maf_save = new_maf\n",
    "        else:\n",
    "            maf_save = pd.concat([maf_save, new_maf], ignore_index=True)\n",
    "    return maf_save, clonal, all_marg\n",
    "\n",
    "def filter_maf_depth(maf, min_total=0, min_alt=0, min_vaf=0):\n",
    "    to_return = maf[maf[\"t_depth\"] >= min_total]\n",
    "    to_return = to_return[to_return[\"t_alt_count\"] >= min_alt]\n",
    "    return to_return[to_return[\"vaf\"] >= min_vaf]\n",
    "\n",
    "def sample_to_patient(sample):\n",
    "    if sample[0] == \"A\":\n",
    "        patient = sample[:4]\n",
    "    else:\n",
    "        patient = sample[:1] + \"001\"\n",
    "    return patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207be114",
   "metadata": {},
   "outputs": [],
   "source": [
    "clonal_WES = None\n",
    "clonal_WGS = None\n",
    "for patient in all_patients_to_process:\n",
    "    print(patient)\n",
    "    prob_mat = np.load(input_dir+patient+WES_npy_postfix)\n",
    "    maf = pd.read_csv(input_dir+patient+WES_maf_postfix)\n",
    "    \n",
    "    maf_save, clonal_add, marg = add_ccfs_count_clonal(prob_mat, maf, purity_dict)\n",
    "    if maf_save is not None:\n",
    "        maf_save.to_csv(output_dir+\"wes/\"+patient+\"_muts_WES_ppVAFs.csv\", index=False)\n",
    "        np.save(output_dir+patient+\"wes/\"+\"_ppVAFmarginalizedPurity_WES.npy\", marg)\n",
    "    if clonal_WES is None:\n",
    "        clonal_WES = clonal_add\n",
    "    else:\n",
    "        clonal_WES = pd.concat([clonal_WES, clonal_add])\n",
    "    \n",
    "    prob_mat = None\n",
    "    \n",
    "    prob_mat = np.load(input_dir+patient+WGS_npy_postfix)\n",
    "    maf = pd.read_csv(input_dir+patient+WGS_maf_postfix)\n",
    "    \n",
    "    maf_save, clonal_add, marg = add_ccfs_count_clonal(prob_mat, maf, purity_dict)\n",
    "    if maf_save is not None:\n",
    "        maf_save.to_csv(output_dir+\"wgs/\"+patient+\"_muts_WGS_ppVAFs.csv\", index=False)\n",
    "        np.save(output_dir+\"wgs/\"+patient+\"_CCFmarginalizedPurity_WGS.npy\", marg)\n",
    "    if clonal_WGS is None:\n",
    "        clonal_WGS = clonal_add\n",
    "    else:\n",
    "        clonal_WGS = pd.concat([clonal_WGS, clonal_add])\n",
    "    \n",
    "    prob_mat = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_maf_WES = None\n",
    "for patient in all_patients_to_process:\n",
    "    try:\n",
    "        maf = pd.read_csv(output_dir+\"wes/\"+patient+\"_muts_WES_ppVAFs.csv\")\n",
    "        #print(len(maf))\n",
    "        if combined_maf_WES is None:\n",
    "            combined_maf_WES = maf\n",
    "        else:\n",
    "            combined_maf_WES = pd.concat([combined_maf_WES, maf])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        \n",
    "combined_maf_WGS = None\n",
    "for patient in all_patients_to_process:\n",
    "    try:\n",
    "        maf = pd.read_csv(output_dir+\"wgs/\"+patient+\"_muts_WGS_ppVAFs.csv\")\n",
    "        if combined_maf_WGS is None:\n",
    "            combined_maf_WGS = maf\n",
    "        else:\n",
    "            combined_maf_WGS = pd.concat([combined_maf_WGS, maf])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "#combined_maf_WGS.to_csv(ccf_dir+\"wgs/\"+\"combined_noshared_muts_WGS.csv\", index=False)\n",
    "#combined_maf_WES.to_csv(ccf_dir+\"wes/\"+\"combined_noshared_muts_WES.csv\", index=False)\n",
    "\n",
    "filtered_maf_WGS = filter_maf_depth(combined_maf_WGS, min_total=10, min_alt=2, min_vaf=0.01)\n",
    "filtered_maf_WES = filter_maf_depth(combined_maf_WES, min_total=10, min_alt=2, min_vaf=0.01)\n",
    "\n",
    "filtered_maf_WGS = filtered_maf_WGS[filtered_maf_WGS[\"purity_ccf\"] > 0]\n",
    "filtered_maf_WES = filtered_maf_WES[filtered_maf_WES[\"purity_ccf\"] > 0]\n",
    "filtered_maf_WGS.to_csv(output_dir+\"wgs/\"+\"combined_noshared_FILTERED_muts_WGS.maf\", index=False, sep=\"\\t\")\n",
    "filtered_maf_WES.to_csv(output_dir+\"wes/\"+\"combined_noshared_FILTERED_muts_WES.maf\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_WES = clonal_WES.set_index(\"sample\")\n",
    "merge_WES[\"has_WES\"] = True\n",
    "\n",
    "merge_WGS = clonal_WGS.set_index(\"sample\")\n",
    "merge_WGS[\"has_WGS\"] = True\n",
    "\n",
    "all_clonal = merge_WES[[\"exp_clonal\", \"CI_clonal\", \"has_WES\"]].join(merge_WGS, lsuffix=\"_WES\", how=\"outer\")\n",
    "all_clonal[\"patient\"] = [sample_to_patient(x) for x in all_clonal.index]\n",
    "\n",
    "all_clonal[\"has_WGS\"] = all_clonal[\"has_WGS\"].fillna(False)\n",
    "all_clonal[\"has_WES\"] = all_clonal[\"has_WES\"].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_stage = dict(zip(combined_maf_WGS[\"Tumor_Sample_Barcode\"], combined_maf_WGS[\"Stage\"]))\n",
    "sample_to_stage.update(dict(zip(combined_maf_WES[\"Tumor_Sample_Barcode\"], combined_maf_WES[\"Stage\"])))\n",
    "all_clonal[\"stage\"] = [sample_to_stage[x] for x in all_clonal.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec509e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WGS_cutoff = 27 + 36\n",
    "WES_cutoff = WGS_cutoff * 0.01\n",
    "\n",
    "all_clonal[\"is_poly\"] = [all_clonal.iloc[i][\"exp_clonal\"] < WGS_cutoff if all_clonal.iloc[i][\"has_WGS\"] else expected_clonal.iloc[i][\"exp_clonal_WES\"] < WES_cutoff for i in range(len(all_clonal))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clonal.to_csv(output_dir+\"wgs_wes/\"+\"clonal_noshared_WES_WGS_polycalls.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
