{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc30718",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a627a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pybedtools, os\n",
    "\n",
    "from CN_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb07819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory containing the .tsv FACETS CN segments files for each dataset. Default repo location given.\n",
    "input_dir = \"../../data/copy_number/\"\n",
    "CN_temp_dir = \"../../data/copy_number/\"\n",
    "resource_dir = \"../../data/resource/\"\n",
    "\n",
    "# names of datasets which you want to process- should match copy number file names.\n",
    "# external datasets (\"PUTH\" and \"SCORT\") not included with our repo- you will have to generate these yourself\n",
    "dataset_names = [\"HTAN_WGS\", \"HTAN_WES\", \"PUTH\", \"SCORT\"]\n",
    "\n",
    "all_unfiltered = []\n",
    "WGD_info = []\n",
    "sample_to_patient = {}\n",
    "for dataset in dataset_names:\n",
    "    data_to_add = pd.read_csv(input_dir+dataset+\"_CN_unfiltered.tsv\", sep=\"\\t\")\n",
    "    all_unfiltered.append(data_to_add)\n",
    "    sample_to_patient.update(dict(zip(data_to_add[\"sample_id\"], data_to_add[\"patient\"])))\n",
    "    doubling_to_add = pd.read_csv(input_dir+\"genome_doubling/\"+dataset+\"_doubled.tsv\", sep=\"\\t\", index_col=0)\n",
    "    WGD_info.append(dict(zip(doubling_to_add.index, doubling_to_add[\"genome_doubled\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f41ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_regions_loc = resource_dir+\"hg38.UCSC.centromere.telomere.encode.bed\"\n",
    "\n",
    "removed_regions = pd.read_csv(removed_regions_loc, sep=\"\\t\", names=[\"chrom\", \"start_pos\", \"end_pos\", \"length\", \"source\", \"reason\"])\n",
    "\n",
    "telomere_table = removed_regions[removed_regions[\"reason\"]==\"telomere\"]\n",
    "\n",
    "telomere_dict = {}\n",
    "for chrom in list(set(telomere_table[\"chrom\"])):\n",
    "    only_chrom = telomere_table[telomere_table[\"chrom\"]==chrom]\n",
    "    telomere_dict[chrom] = [only_chrom.iloc[0][\"end_pos\"], only_chrom.iloc[1][\"start_pos\"]]\n",
    "    \n",
    "genome_len = sum([telomere_dict[x][1]-telomere_dict[x][0] if not x in [\"chrX\", \"chrY\"] else 0 for x in telomere_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dbc765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182768/3769358819.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  to_save[\"seg_ID\"] = [to_save.iloc[i][\"sample_id\"]+\"_\"+str(i) for i in range(len(to_save))]\n",
      "/tmp/ipykernel_182768/3769358819.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  to_save[\"seg_ID\"] = [to_save.iloc[i][\"sample_id\"]+\"_\"+str(i) for i in range(len(to_save))]\n",
      "/tmp/ipykernel_182768/3769358819.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  to_save[\"seg_ID\"] = [to_save.iloc[i][\"sample_id\"]+\"_\"+str(i) for i in range(len(to_save))]\n",
      "/tmp/ipykernel_182768/3769358819.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  to_save[\"seg_ID\"] = [to_save.iloc[i][\"sample_id\"]+\"_\"+str(i) for i in range(len(to_save))]\n"
     ]
    }
   ],
   "source": [
    "CN_dir_loc = CN_temp_dir + \"overlap_filtered_beds/\"\n",
    "os.makedirs(CN_dir_loc, exist_ok=True)\n",
    "overlap_threshold = 0.3\n",
    "\n",
    "blacklist_filtered = []\n",
    "for i,save_df in enumerate(all_unfiltered):\n",
    "    save_name = dataset_names[i]\n",
    "    save_loc = CN_dir_loc+save_name+\"_unfiltered.bed\"\n",
    "    to_save = save_df[[\"chrom\", \"loc_start\", \"loc_end\", \"sample_id\"]]\n",
    "    to_save[\"seg_ID\"] = [to_save.iloc[i][\"sample_id\"]+\"_\"+str(i) for i in range(len(to_save))]\n",
    "    to_save.to_csv(save_loc, header=False, index=False, sep=\"\\t\")\n",
    "    to_filter = save_df.copy()\n",
    "    to_filter.index = to_save[\"seg_ID\"]\n",
    "    \n",
    "    filtered_loc = CN_dir_loc+save_name+\"_overlap_filtered.bed\"\n",
    "    bed_to_intersect = pybedtools.BedTool(save_loc)\n",
    "    bed_to_intersect.intersect(removed_regions_loc, f=overlap_threshold, v=True).saveas(filtered_loc)\n",
    "    filtered_df = pd.read_csv(filtered_loc, sep=\"\\t\", names=[\"chrom\", \"loc_start\", \"loc_end\", \"sample_id\", \"seg_ID\"])\n",
    "\n",
    "    blacklist_filtered.append(to_filter.loc[filtered_df[\"seg_ID\"]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f822c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_threshold = 1e6\n",
    "cf_threshold = 0.15\n",
    "    \n",
    "length_filtered = []\n",
    "for to_filter in blacklist_filtered:\n",
    "    to_filter[\"length\"] = to_filter[\"loc_end\"] - to_filter[\"loc_start\"]\n",
    "    length_filtered.append(to_filter[to_filter[\"length\"] > len_threshold])\n",
    "    \n",
    "cf_filtered = []\n",
    "for to_filter in length_filtered:\n",
    "    cf_filtered.append(to_filter[to_filter[\"cf_em\"] > cf_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2661411a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/software/user/open/py-pandas/1.3.1_py39/lib/python3.9/site-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cacher_needs_updating = self._check_is_chained_assignment_possible()\n",
      "/share/software/user/open/py-pandas/1.3.1_py39/lib/python3.9/site-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cacher_needs_updating = self._check_is_chained_assignment_possible()\n",
      "/share/software/user/open/py-pandas/1.3.1_py39/lib/python3.9/site-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cacher_needs_updating = self._check_is_chained_assignment_possible()\n",
      "/share/software/user/open/py-pandas/1.3.1_py39/lib/python3.9/site-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cacher_needs_updating = self._check_is_chained_assignment_possible()\n"
     ]
    }
   ],
   "source": [
    "bed_columns = [\"chrom\", \"loc_start\", \"loc_end\", \"tcn_em\", \"lcn_em\"]\n",
    "bed_to_intersect = pybedtools.BedTool(resource_dir+\"hg38_gene_locs.bed\")\n",
    "\n",
    "for i,to_save in enumerate(cf_filtered):\n",
    "    save_name = dataset_names[i]\n",
    "    merged = extend_merge_all(to_save, telomere_dict, WGD_info[i])\n",
    "    all_samples = list(set(merged[\"sample_id\"]))\n",
    "    \n",
    "    bed_dir_path = CN_temp_dir+\"final_filtered_beds/\"+save_name+\"/\"\n",
    "    os.makedirs(bed_dir_path, exist_ok=True)\n",
    "    \n",
    "    gene_dir_path = CN_temp_dir+\"gene_overlap_beds/\"+save_name+\"/\"\n",
    "    os.makedirs(gene_dir_path, exist_ok=True)\n",
    "    for sample in all_samples:\n",
    "        merged_CN_bed_loc = bed_dir_path+sample+\"_filtered_merged.bed\"\n",
    "        only_sample = merged[merged[\"sample_id\"]==sample]\n",
    "        only_sample[bed_columns].to_csv(merged_CN_bed_loc, header=False, index=False, sep=\"\\t\", na_rep=\"NaN\")\n",
    "        \n",
    "        gene_intersect_bed_loc = gene_dir_path+sample+\"_gene_overlaps.bed\"\n",
    "        bed_to_intersect.intersect(merged_CN_bed_loc, wb=True).saveas(gene_intersect_bed_loc)\n",
    "    \n",
    "    to_save.to_csv(input_dir+save_name+\"_CN_filtered.tsv\", index=False, sep=\"\\t\")\n",
    "    merged.to_csv(input_dir+save_name+\"_CN_filtered_merged.tsv\", index=False, sep=\"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0da9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_genes = len(pd.read_csv(resource_dir+\"hg38_gene_locs.bed\", sep=\"\\t\", header=None))    \n",
    "\n",
    "all_gene_calls = []\n",
    "for i,to_save in enumerate(cf_filtered):\n",
    "    save_name = dataset_names[i]\n",
    "    \n",
    "    gene_dir_path = CN_temp_dir+\"gene_overlap_beds/\"+save_name+\"/\"\n",
    "    all_samples = list(set(to_save[\"sample_id\"]))\n",
    "    \n",
    "    to_concat = []\n",
    "    for sample in all_samples:\n",
    "        gene_intersect_bed_loc = gene_dir_path+sample+\"_gene_overlaps.bed\"\n",
    "        gene_overlaps = pd.read_csv(gene_intersect_bed_loc, sep=\"\\t\", header=None, names=[\"gene_chrom\", \"gene_start\", \"gene_end\", \"gene_name\", \"seg_chrom\", \"seg_start\", \"seg_end\", \"tcn_em\", \"lcn_em\"])\n",
    "        gene_overlaps = deduplicate_gene_calls(gene_overlaps)\n",
    "        add_CN_types(gene_overlaps, sample_to_patient[sample], WGD_info[i][sample])\n",
    "        gene_overlaps[\"sample_id\"] = sample\n",
    "        \n",
    "        assert len(gene_overlaps) == number_of_genes, \"wrong number of total gene CN calls\"\n",
    "        \n",
    "        to_concat.append(gene_overlaps)\n",
    "    all_gene_calls.append(pd.concat(to_concat))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f222c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(input_dir+\"gene_CN_calls/\", exist_ok=True)\n",
    "for i,to_save in enumerate(all_gene_calls):\n",
    "    save_name = dataset_names[i]\n",
    "    to_save.to_csv(input_dir+\"gene_CN_calls/\"+save_name+\"_gene_CNs.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd74b46c",
   "metadata": {},
   "source": [
    "## APPENDIX: making a gene to genomic location table from the GRCh38 reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ce556dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "grch38_gff_loc = \"\" #path to gencode.v33.basic.annotation.gff3.gz\n",
    "grch38_genes = pd.read_csv(grch38_gff_loc, comment=\"#\", compression=\"gzip\", sep=\"\\t\", header=None, names=[\"chrom\", \"source\", \"type\", \"start\", \"end\", \"nothing\", \"strand\", \"nothing2\", \"info\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d32e4170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11996/2480974357.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  only_genes[\"gene_name\"] = [parse_info_column(x) for x in only_genes[\"info\"]]\n"
     ]
    }
   ],
   "source": [
    "def parse_info_column(info):\n",
    "    splitted = info.split(\";\")\n",
    "    for token in splitted:\n",
    "        pair = token.split(\"=\")\n",
    "        if pair[0] == \"gene_name\":\n",
    "            return pair[1]\n",
    "    return \"NONE\"\n",
    "\n",
    "only_genes = grch38_genes[grch38_genes[\"type\"]==\"gene\"]\n",
    "only_genes[\"gene_name\"] = [parse_info_column(x) for x in only_genes[\"info\"]]\n",
    "only_genes = only_genes[~np.isin(only_genes[\"chrom\"], [\"chrY\", \"chrM\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96a8196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_names = only_genes.value_counts(\"gene_name\")\n",
    "duplicate_names = duplicate_names[duplicate_names > 1]\n",
    "\n",
    "deduplicated = []\n",
    "for gene in duplicate_names.index:\n",
    "    both_listings = only_genes[only_genes[\"gene_name\"]==gene]\n",
    "    to_add = pd.DataFrame(both_listings.iloc[0]).transpose()\n",
    "    to_add[\"start\"] = np.min(both_listings[\"start\"])\n",
    "    to_add[\"end\"] = np.max(both_listings[\"end\"])\n",
    "    deduplicated.append(to_add)\n",
    "    \n",
    "deduplicated = pd.concat(deduplicated)\n",
    "only_genes = only_genes[~np.isin(only_genes[\"gene_name\"], duplicate_names.index)]\n",
    "only_genes = pd.concat([only_genes, deduplicated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9da4cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "grch38_to_bed = only_genes[[\"chrom\", \"start\", \"end\", \"gene_name\"]]\n",
    "grch38_to_bed.to_csv(resource_dir+\"hg38_gene_locs.bed\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09c234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_sherlock",
   "language": "python",
   "name": "py39_sherlock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
