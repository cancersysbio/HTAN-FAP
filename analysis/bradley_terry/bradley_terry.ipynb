{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing Bradley Terry Model Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import joypy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sys\n",
    "from matplotlib import cm\n",
    "\n",
    "sys.path.append(\"/Users/ryanschenck/Dropbox/Projects/FAP_Project/mutation_timing\")\n",
    "from BTmodel import run\n",
    "\n",
    "font = {'size'   : 8}\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load resources\n",
    "\n",
    "List of known drivers used as potential genes in Bradley Terry model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cancer_drivers(driverfile=\"data/resource/PanCanDrivers_Cell2018.csv\"):\n",
    "    x = pd.read_csv(driverfile,skiprows=3)\n",
    "    listofgenes = x[\"Gene\"]\n",
    "    return (list(set(listofgenes)))\n",
    "\n",
    "drivers = get_cancer_drivers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htan = \"data/combined_noshared_FILTERED_muts_WGS.csv\"\n",
    "df = pd.read_csv(htan, low_memory=False)\n",
    "df['WXS'] = 'WGS'\n",
    "\n",
    "htanwes = \"data/combined_noshared_FILTERED_muts_WES.csv\"\n",
    "dfwes = pd.read_csv(htanwes, low_memory=False)\n",
    "dfwes['WXS'] = 'WES'\n",
    "\n",
    "df = pd.concat([df, dfwes]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure CLONAL/SUBCLONAL are strings and reduce clonality calls to SUBCLONAL/CLONAL\n",
    "df['binary_clonal'] = df['purity_clonal'].apply(lambda x: 0 if 'SUBCLONAL' in x else 1)\n",
    "df['clonality'] = df['purity_clonal'].apply(lambda x: 'SUBCLONAL' if 'SUBCLONAL' in x else 'CLONAL')\n",
    "\n",
    "# Only use these columns\n",
    "df = df[['Patient', 'Mut_ID', 'WXS', 'Tumor_Sample_Barcode', 'Hugo_Symbol', 'Driver', 'Stage', 'clonality', 'binary_clonal', 'tcn.sequenza', 'ln.sequenza']].reset_index(drop=True)\n",
    "\n",
    "# Take only WGS mutations where WES and WGS are both available\n",
    "dups = df[df.duplicated(subset=['Patient', 'Mut_ID', 'Tumor_Sample_Barcode', 'Hugo_Symbol', 'Driver', 'Stage'], keep=False)].reset_index(drop=True)\n",
    "nondups = df[~df.duplicated(subset=['Patient', 'Mut_ID', 'Tumor_Sample_Barcode', 'Hugo_Symbol', 'Driver', 'Stage'], keep=False)].reset_index(drop=True)\n",
    "\n",
    "# Keep only the WGS record for duplicates\n",
    "dups = dups[dups['WXS']=='WGS'].reset_index(drop=True)\n",
    "\n",
    "# Combine the two\n",
    "df = pd.concat([nondups, dups]).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Li et al. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pku = '/Users/ryanschenck/Dropbox/Projects/FAP_Project/data/HTAN_FAP_MAFs/snpconsensus/PKU_samples.snpconsensus.filtered.mpileups_filtered.ccfs.ccfs_noprobs.maf'\n",
    "dfpku = pd.read_csv(pku, sep='\\t', low_memory=False)[['Patient', 'Mut_ID', 'WXS', 'Tumor_Sample_Barcode', 'Hugo_Symbol', 'Driver',  'Stage', 'ccf_expected_copies', 'clonality', 'tcn.sequenza', 'ln.sequenza']]\n",
    "\n",
    "dfpku['binary_clonal'] = dfpku['clonality'].apply(lambda x: 0 if 'SUBCLONAL' in str(x) else 1)\n",
    "dfpku.rename(columns={'ccf_expected_copies':'purity_ccf', 'binary_clonal':'binary_clonal'}, inplace=True)\n",
    "dfpku = dfpku[['Patient', 'Mut_ID', 'WXS', 'Tumor_Sample_Barcode', 'Hugo_Symbol', 'Driver', 'Stage', 'clonality', 'binary_clonal', 'tcn.sequenza', 'ln.sequenza']].reset_index(drop=True)\n",
    "\n",
    "# Break Tumor Sample Barcode into Patient and Sample and Region\n",
    "dfpku['Sample'] = dfpku['Tumor_Sample_Barcode'].str.split('_').str[1]\n",
    "dfpku['Region'] = dfpku['Tumor_Sample_Barcode'].str.split('_').str[2]\n",
    "\n",
    "# Get duplicates for dfpku based on Sample and Region\n",
    "dups = dfpku[dfpku.duplicated(subset=['Patient', 'Mut_ID', 'Sample', 'Hugo_Symbol', 'Driver', 'Stage'], keep=False)].reset_index(drop=True)\n",
    "nondups = dfpku[~dfpku.duplicated(subset=['Patient', 'Mut_ID', 'Sample', 'Hugo_Symbol', 'Driver', 'Stage'], keep=False)].reset_index(drop=True)\n",
    "\n",
    "# Keep the 'CLONAL' record for duplicates as maximum observed, or subclonal if no clonal present\n",
    "keepers = []\n",
    "for s, sdf in dups.groupby(['Patient','Sample','Mut_ID']):\n",
    "    # Check if there's a clonal record clonality\n",
    "    if 'CLONAL' in sdf['clonality'].values:\n",
    "        clonal = sdf[sdf['clonality']=='CLONAL']\n",
    "        if len(clonal) > 1:\n",
    "            # Take only the first row index\n",
    "            idx = clonal.index[0]\n",
    "            keepers.append(idx)\n",
    "        else:\n",
    "            keepers.append(clonal.index[0])\n",
    "    else:\n",
    "        # Take first row\n",
    "        keepers.append(sdf.index[0])\n",
    "\n",
    "keepers = dups.loc[keepers]\n",
    "\n",
    "# Combine cleaned dataset\n",
    "dfpku = pd.concat([nondups, keepers]).reset_index(drop=True)\n",
    "\n",
    "# Check to make sure no duplicates now\n",
    "dups = dfpku[dfpku.duplicated(subset=['Patient', 'Mut_ID', 'Sample', 'Hugo_Symbol', 'Driver', 'Stage'], keep=False)].reset_index(drop=True)\n",
    "assert dups.shape[0] == 0, 'Duplicates still present, check code'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver status changed to boolean (previous iterations of SNVs had it as a string/boolean/binary)\n",
    "\n",
    "# HTAN DATA\n",
    "htan_drivers = df[(df['Hugo_Symbol'].isin(drivers)) & (df['Driver']==True)].reset_index(drop=True)\n",
    "htan_drivers['Driver'] = htan_drivers['Driver'].apply(lambda x: True if x else False)\n",
    "\n",
    "# PKU DATA\n",
    "pku_drivers = dfpku[(dfpku['Hugo_Symbol'].isin(drivers)) & (dfpku['Driver']==True)].reset_index(drop=True)\n",
    "pku_drivers['Driver'] = pku_drivers['Driver'].apply(lambda x: True if x else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cohort column\n",
    "htan_drivers['Cohort'] = 'HTAN'\n",
    "pku_drivers['Cohort'] = 'PKU'\n",
    "\n",
    "# Combine\n",
    "driverDf = pd.concat([htan_drivers, pku_drivers]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Mucosa samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driverDf = driverDf[~driverDf['Stage'].str.contains('Mucosa')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for the number of driver mutations per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = driverDf['Hugo_Symbol'].value_counts()\n",
    "# Sort by counts\n",
    "total_counts = total_counts.sort_values(ascending=False).reset_index(drop=False)\n",
    "total_counts.columns = ['Hugo_Symbol','Count']\n",
    "\n",
    "# Counts by cohort\n",
    "cohort_counts = driverDf.groupby(['Hugo_Symbol','Cohort']).size().reset_index(drop=False).rename(columns={0:'Count'})\n",
    "# Sort by Hugo_Symbol and Cohort\n",
    "\n",
    "# Get counts for each stage\n",
    "stage_counts = driverDf.groupby(['Hugo_Symbol','Stage']).size().reset_index(drop=False).rename(columns={0:'Count'})\n",
    "# Sort by Hugo_Symbol and Cohort\n",
    "stage_counts = stage_counts.sort_values(by=['Hugo_Symbol','Stage']).reset_index(drop=True)\n",
    "\n",
    "# Get counts by Stage and Cohort\n",
    "stage_cohort_counts = driverDf.groupby(['Hugo_Symbol','Stage','Cohort']).size().reset_index(drop=False).rename(columns={0:'Count'})\n",
    "# Sort by Hugo_Symbol and Cohort\n",
    "stage_cohort_counts = stage_cohort_counts.sort_values(by=['Hugo_Symbol','Stage','Cohort']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of driver mutations per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each as stacked bar for each cohort\n",
    "fig, ax = plt.subplots(3,1,figsize=(16,10))\n",
    "\n",
    "def plot_counts(data, ax, group=None, title=\"\", threshold=0):\n",
    "    # Ensure data sorted by count\n",
    "    data = data.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    if group is None:\n",
    "        # Add group based on threshold\n",
    "        data['Driver Count'] = data['Count'].apply(lambda x: f'â‰¥{threshold}' if x > threshold else f'<{threshold}')\n",
    "        sns.barplot(x='Hugo_Symbol', y='Count', data=data, hue='Driver Count', ax=ax, palette='Set2')\n",
    "\n",
    "        # Add count to top of each bar\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=6)\n",
    "    else:\n",
    "        # Stacked barchart by group\n",
    "        sns.barplot(x='Hugo_Symbol', y='Count', data=data, hue=group, ax=ax, palette='Set2')\n",
    "        \n",
    "\n",
    "    # Rotate x labels\n",
    "    for item in ax.get_xticklabels():\n",
    "        item.set_rotation(90)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Log scale\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    # Ax\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "plot_counts(total_counts, ax[0], group=None, title='All FAP cohorts and stages', threshold=1)\n",
    "\n",
    "plot_counts(cohort_counts, ax[1], group='Cohort', title='All FAP cohorts by cohort', threshold=1)\n",
    "\n",
    "plot_counts(stage_counts, ax[2], group='Stage', title='All FAP cohorts by stage', threshold=1)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bradley Terry Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def bradleyterry(df, wd=\"analysis/bradley_terry/preferential_ordering/wd\"):\n",
    "    df.to_csv(\"%s/tmp.csv\" % (wd), index=False)\n",
    "    cmd = \"Rscript analysis/bradley_terry/preferential_ordering/bradleyterry.R %s/tmp.csv %s\" % (wd, wd)\n",
    "\n",
    "    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode==1:\n",
    "        print(process.stdout.read().decode(\"utf-8\"))\n",
    "        print(process.stderr.read().decode(\"utf-8\"))\n",
    "        print(df.shape)\n",
    "        raise Exception(\"Error in R script\")\n",
    "    else:\n",
    "        os.remove(\"%s/tmp.csv\" % (wd))\n",
    "        df = pd.read_csv(\"%s/tmp_out.csv\" % (wd))\n",
    "        os.remove(\"%s/tmp_out.csv\" % (wd))\n",
    "        return(df)\n",
    "\n",
    "def get_cancer_drivers(driverfile=\"data/resource/PanCanDrivers_Cell2018.csv\"):\n",
    "    x = pd.read_csv(driverfile,skiprows=3)\n",
    "    listofgenes = x[\"Gene\"]\n",
    "    return (list(set(listofgenes)))\n",
    "\n",
    "def frequencyOfWinners(df, by='Tumor_Sample_Barcode', clonality_col='clonality'):\n",
    "    genes = df['Hugo_Symbol'].unique().tolist()\n",
    "\n",
    "    # calculate frequency of gene 1 occuring before gene 2\n",
    "    ret = []\n",
    "    pairs = []\n",
    "    samples_with_pair = []\n",
    "    n_sample_in_pair = []\n",
    "\n",
    "    n=1\n",
    "    for i in range(len(genes)):\n",
    "      # print(i)\n",
    "      # select mutations of interest\n",
    "\n",
    "      gene_1 = genes[i]\n",
    "\n",
    "      for j in range(i+1, len(genes)):\n",
    "        # print(j)\n",
    "        # j <- 2\n",
    "        gene_2 = genes[j]\n",
    "\n",
    "        if gene_1 != gene_2:\n",
    "            # if gene_1!='toss' and gene_2!='toss':\n",
    "            # record two pairs\n",
    "            pairs.append((gene_1, gene_2))\n",
    "\n",
    "            # select patients with both mutations\n",
    "            samplesWithMuts = df[(df['Hugo_Symbol'].isin([gene_1, gene_2]))]\n",
    "            groups = samplesWithMuts.groupby(by)\n",
    "\n",
    "            samplesRet = []\n",
    "            n_1_before_2 = 0\n",
    "            n_2_before_1 = 0\n",
    "            for g, gdf in groups:\n",
    "                clonality_gene1 = gdf[(gdf['Hugo_Symbol'] == gene_1) & (\n",
    "                        gdf[clonality_col] == 'CLONAL')].shape[0]\n",
    "                clonality_gene2 = gdf[(gdf['Hugo_Symbol'] == gene_2) & (\n",
    "                        gdf[clonality_col] == 'CLONAL')].shape[0]\n",
    "                if gdf['Hugo_Symbol'].unique().shape[0]>=2:\n",
    "                    samplesRet.append(gdf)\n",
    "\n",
    "                    if clonality_gene1 > clonality_gene2:\n",
    "                        n_1_before_2+=1\n",
    "                    elif clonality_gene1 < clonality_gene2:\n",
    "                        n_2_before_1+=1\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    # This is where the mutation occurs as clonal without the other...this should be a win.\n",
    "                    if clonality_gene1>0:\n",
    "                        n_1_before_2 += 1\n",
    "                    elif clonality_gene1>0:\n",
    "                        n_2_before_1 += 1\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "            ret.append(pd.DataFrame({ 'gene_1':[gene_1], 'gene_2':[gene_2], 'n_1_before_2':[n_1_before_2], 'n_2_before_1':[n_2_before_1] }))\n",
    "    if len(ret)>0:\n",
    "        ret = pd.concat(ret)\n",
    "        # Remove cases with zero wins in the gene1 vs gene2 pair\n",
    "        counts = ret[ret[['n_1_before_2', 'n_2_before_1']].sum(axis=1) > 0].reset_index(drop=True)\n",
    "        # if counts[counts['gene_1']=='DMD'].shape[0] > 0:\n",
    "        #     print('DMD Found')\n",
    "        return (counts)\n",
    "    else:\n",
    "        return (pd.DataFrame())\n",
    "\n",
    "def loo_loop(gdf, ret, by, group, wd=\"analysis/bradley_terry/preferential_ordering/wd\", clonality_col='clonality'):\n",
    "    '''\n",
    "    Leave one out loop for the Bradley Terry model\n",
    "\n",
    "    :param gdf: dataframe of mutation winners\n",
    "    :param ret: list to hold results\n",
    "    :param by: factor to group by (e.g. 'Stage')\n",
    "    :param group: group name (e.g. 'Dysplasia')\n",
    "    :return: ret, list of results now filled\n",
    "    '''\n",
    "    samples = gdf['Tumor_Sample_Barcode'].unique().tolist()\n",
    "    for i in tqdm(range(len(samples)), desc=\"Running leave one out loop for %s\" % (group)):\n",
    "        gdf_all_but_1 = gdf[gdf['Tumor_Sample_Barcode'] != samples[i]]\n",
    "        # Get frequency of winners\n",
    "        frequencies = frequencyOfWinners(gdf_all_but_1, clonality_col=clonality_col)\n",
    "        if frequencies.shape[0] > 1:\n",
    "            bt_out = bradleyterry(frequencies, wd=wd)\n",
    "            bt_out[by] = group\n",
    "            bt_out['loo_sample'] = samples[i]\n",
    "            ret.append(bt_out)\n",
    "        # else:\n",
    "            # print(\"No winners for %s\" % (group))\n",
    "    return(ret)\n",
    "\n",
    "def bootstrap_loop(gdf, ret, by, group, n=100, wd=\"analysis/bradley_terry/preferential_ordering/wd\", clonality_col='clonality'):\n",
    "    samples = gdf['Tumor_Sample_Barcode'].unique().tolist()\n",
    "    for i in tqdm(range(n)):\n",
    "        samples_to_run = np.random.choice(samples, int(np.floor(len(samples)*.75)), replace=False)\n",
    "        gdf_boot = [gdf[gdf['Tumor_Sample_Barcode'] == samples_to_run[j]].reset_index(drop=True) for j in range(len(samples_to_run))]\n",
    "        boot_samples = []\n",
    "        for k, sam in enumerate(gdf_boot):\n",
    "            sam['boot_sam_num'] = k\n",
    "            boot_samples.append(sam)\n",
    "        gdf_boot = pd.concat(boot_samples, axis=0).reset_index(drop=True)\n",
    "        # Get frequency of winners\n",
    "        frequencies = frequencyOfWinners(gdf_boot, by='boot_sam_num', clonality_col=clonality_col)\n",
    "        if frequencies.shape[0] > 1:\n",
    "            bt_out = bradleyterry(frequencies, wd=wd)\n",
    "            bt_out[by] = group\n",
    "            bt_out['bootstrap_run'] = i\n",
    "            ret.append(bt_out)\n",
    "        else:\n",
    "            print(\"No winners for %s\" % (group))\n",
    "    return (ret)\n",
    "\n",
    "def run(df, allSamples=True, by=\"Stage\", bootstrap=False, wd=\"analysis/bradley_terry/preferential_ordering/wd\", loo_func=False, clonality_col='clonality'):\n",
    "    '''\n",
    "    Runs the bradley terry model\n",
    "\n",
    "    :param df: dataframe of mutations with clonality\n",
    "    :param allSamples: boolean, if True, run on all samples together, if False, run on samples with at least 2 mutations\n",
    "    :param by: factor to group by (e.g. 'Stage'), must be specified if allSamples=False\n",
    "    :param bootstrap: boolean, if True, run leave one out loop\n",
    "    :return: Bradley Terry results\n",
    "    '''\n",
    "    if allSamples and bootstrap==False:\n",
    "        # Run on all samples together\n",
    "        frequencies = frequencyOfWinners(df, clonality_col=clonality_col)\n",
    "        bt_out = bradleyterry(frequencies, wd=wd)\n",
    "        bt_out[by] = 'All Samples'\n",
    "        return (bt_out)\n",
    "    elif allSamples and bootstrap:\n",
    "        # run bootstrap loop on all samples\n",
    "        ret = []\n",
    "        if loo_func:\n",
    "            ret = loo_loop(df, ret, by, 'All Samples', wd=wd, clonality_col=clonality_col)\n",
    "        else:\n",
    "            ret = bootstrap_loop(df, ret, by, 'All Samples', wd=wd, clonality_col=clonality_col)\n",
    "        if len(ret) > 0:\n",
    "            bt_out = pd.concat(ret, axis=0).reset_index(drop=True)\n",
    "            bt_out[by] = 'All Samples'\n",
    "            return (bt_out)\n",
    "        else:\n",
    "            return (np.nan)\n",
    "    elif allSamples==False and bootstrap==False:\n",
    "        # Run by stage\n",
    "        ret = []\n",
    "        for group, gdf in df.groupby(by):\n",
    "            print(\"Running group: %s\\n\" % (group))\n",
    "            if gdf.shape[0]>0:\n",
    "                # Get frequency of winners\n",
    "                frequencies = frequencyOfWinners(gdf, clonality_col=clonality_col)\n",
    "                if frequencies.shape[0]>0:\n",
    "                    bt_out = bradleyterry(frequencies, wd=wd)\n",
    "                    bt_out[by] = group\n",
    "                    ret.append(bt_out)\n",
    "                else:\n",
    "                    print(\"No winners for %s\" % (group))\n",
    "            else:\n",
    "                print(\"No samples in group %s\" % (group))\n",
    "        if len(ret)>0:\n",
    "            ret = pd.concat(ret, axis=0).reset_index(drop=True)\n",
    "            return ( ret )\n",
    "        else:\n",
    "            return (np.nan)\n",
    "    elif allSamples==False and bootstrap:\n",
    "        ret = []\n",
    "        for group, gdf in df.groupby(by):\n",
    "            print(\"Running group: %s\\n\" % (group))\n",
    "            if gdf.shape[0] > 0:\n",
    "                # Run the per sample leave one out loop\n",
    "                # ret = bootstrap_loop(gdf, ret, by, group, wd=wd)\n",
    "                if loo_func:\n",
    "                    ret = loo_loop(gdf, ret, by, group, wd=wd, clonality_col=clonality_col)\n",
    "                else:\n",
    "                    ret = bootstrap_loop(gdf, ret, by, group, wd=wd, clonality_col=clonality_col)\n",
    "            else:\n",
    "                print(\"No samples in group %s\" % (group))\n",
    "        if len(ret) > 0:\n",
    "            ret = pd.concat(ret, axis=0).reset_index(drop=True)\n",
    "            return (ret)\n",
    "        else:\n",
    "            return (np.nan)\n",
    "    else:\n",
    "        raise Exception(\"Invalid combination of parameters\")\n",
    "\n",
    "def plotResults(btdf):\n",
    "    n_stages = btdf['Stage'].unique().shape[0]\n",
    "\n",
    "    fig, axs = plt.subplots(n_stages, 1, figsize=(10, 10))\n",
    "    i = 0\n",
    "    for g, groupdf in btdf.groupby('Stage'):\n",
    "        groupdf = groupdf[groupdf['Pr(>|z|)'] <= 0.05]\n",
    "        groupdf = groupdf.sort_values('Estimate', ascending=True)\n",
    "\n",
    "        if groupdf.shape[0] > 0:\n",
    "            ax = axs[i]\n",
    "            sns.boxplot(x='gene', y='rankOrder', data=groupdf, ax=ax)\n",
    "            ax.set_title(g)\n",
    "            ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "            ax.set_xlabel('')\n",
    "        i += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# def main():\n",
    "#     # Get system arguments for maf file and working directory\n",
    "#     maf_file = sys.argv[1] # File with mutations, this should be a parquet file\n",
    "#     wd = sys.argv[2] # Working directory\n",
    "#     outname = sys.argv[3] # Output name\n",
    "\n",
    "#     # maf_file = \"/Users/ryanschenck/Dropbox/Projects/FAP_Project/data/vcfs/FAP_samples.correctedCCF.parquet\"\n",
    "#     # wd = \"/Users/ryanschenck/Dropbox/Projects/FAP_Project/mutation_timing\"\n",
    "#     # outname = \"loo_bootstrap\"\n",
    "\n",
    "#     # Load the maf file\n",
    "#     mutDf = pq.read_pandas(maf_file).to_pandas()\n",
    "#     # mutDf = mutDf[mutDf['Variant_Classification'].isin(['Missense_Mutation', 'Nonsense_Mutation', 'Translation_Start_Site'])]\n",
    "#     mutDf = mutDf[mutDf['Driver']==True]\n",
    "\n",
    "#     # Load known drivers\n",
    "#     drivers = get_cancer_drivers()\n",
    "#     # drivers = drivers[0:20] # subset for dev testing\n",
    "\n",
    "#     driverDf = mutDf[mutDf['Hugo_Symbol'].isin(drivers)].reset_index(drop=True)\n",
    "\n",
    "#     # Run across all samples combined\n",
    "#     loopFunc = False\n",
    "#     print(\"Running BT across all samples\")\n",
    "#     if outname == \"loo\":\n",
    "#         loopFunc = True\n",
    "#     btretAllFAPSamples = run(driverDf, allSamples=True, bootstrap=True, by=\"Stage2\", wd=wd, loo_func=loopFunc)\n",
    "\n",
    "#     # Run across samples by stage\n",
    "#     print(\"Running BT across each stage\")\n",
    "#     driverDf['Stage2'] = driverDf['Stage'].apply(lambda x: \"Dysplasia + AdCa\" if x in ['Dysplasia', 'AdCa'] else x)\n",
    "#     if outname == \"loo\":\n",
    "#         loopFunc = True\n",
    "#     btret = run(driverDf, allSamples=False, by=\"Stage2\", bootstrap=True, wd=wd, loo_func=loopFunc)\n",
    "\n",
    "#     # Combine Runs\n",
    "#     btret = pd.concat([btretAllFAPSamples, btret], axis=0).reset_index(drop=True)\n",
    "\n",
    "#     # Output results for visualizations\n",
    "#     outputfile = os.path.basename(maf_file).replace('.parquet', '.bradleyterry.') + outname + '.csv'\n",
    "#     btret.to_csv(\"%s/%s\" % (wd, outputfile), index=False)\n",
    "\n",
    "#     print(btret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Bradley Terry Model without thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = \"loo_bootstrap\"\n",
    "wd = \"analysis/bradley_terry/preferential_ordering/wd/\"\n",
    "\n",
    "# Run across all samples combined\n",
    "loopFunc = False\n",
    "\n",
    "# Run across samples by stage\n",
    "print(\"Running BT across each stage\")\n",
    "driverDf['Stage2'] = driverDf['Stage'].apply(lambda x: \"Dysplasia\" if x in ['Dysplasia'] else x)\n",
    "if outname == \"loo\":\n",
    "    loopFunc = True\n",
    "btret = run(driverDf, allSamples=False, by=\"Stage2\", bootstrap=True, wd=wd, loo_func=loopFunc, clonality_col='clonality', threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bradley Terry Model with thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 2\n",
    "\n",
    "# Subset where count hugo_symbol is present more than once in total_counts and stage_counts\n",
    "total_counts_subset = total_counts[total_counts['Count']>thresh]['Hugo_Symbol'].unique().tolist()\n",
    "\n",
    "benign_thresh_genes = stage_counts[(stage_counts['Count']>thresh) & (stage_counts['Stage'].isin(['Benign']))]['Hugo_Symbol'].unique().tolist()\n",
    "\n",
    "dysplasia_thresh_genes = stage_counts[(stage_counts['Count']>thresh) & (stage_counts['Stage'].isin(['Dysplasia', 'AdCa']))]['Hugo_Symbol'].unique().tolist()\n",
    "\n",
    "# Subest by stage and count\n",
    "benign = driverDf[(driverDf['Hugo_Symbol'].isin(benign_thresh_genes)) & (driverDf['Stage'].isin(['Benign']))].reset_index(drop=True)\n",
    "\n",
    "# Subset by stage and count\n",
    "dysplasia = driverDf[(driverDf['Hugo_Symbol'].isin(dysplasia_thresh_genes)) & (driverDf['Stage'].isin(['Dysplasia', 'AdCa']))].reset_index(drop=True)\n",
    "\n",
    "# Combine\n",
    "driverDfSubset = pd.concat([benign, dysplasia]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = \"loo_bootstrap.thresh_2\"\n",
    "wd = \"analysis/bradley_terry/preferential_ordering/wd\"\n",
    "\n",
    "# # Run across all samples combined\n",
    "loopFunc = False\n",
    "\n",
    "# Run across samples by stage\n",
    "print(\"Running BT across each stage\")\n",
    "driverDfSubset['Stage2'] = driverDfSubset['Stage'].apply(lambda x: \"Dysplasia\" if x in ['Dysplasia','AdCa'] else x)\n",
    "# driverDfBCI['Stage2'] = driverDfBCI['Stage']\n",
    "if outname == \"loo\":\n",
    "    loopFunc = True\n",
    "btret = run(driverDfSubset, allSamples=False, by=\"Stage2\", bootstrap=True, wd=wd, loo_func=loopFunc, clonality_col='clonality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "# Output results for visualizations\n",
    "outputfile = f'{outname}.bradleyterry.csv'\n",
    "btret.to_csv(\"%s\" % (outputfile), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_method = 'bootstrap_run' # loo_sample or bootstrap_run\n",
    "statistic = 'Pr(>|z|)' # fdr or Pr(>|z|)\n",
    "\n",
    "combined_datasets = []\n",
    "dataset_names = ['FAP']\n",
    "for dataidx, dataset in enumerate([outputfile]):\n",
    "    print(dataset)\n",
    "    if bootstrap_method == 'bootstrap_run':\n",
    "        btret = pd.read_csv(dataset, low_memory=False)\n",
    "        btret['Stage2'] = btret['Stage2'].apply(lambda x: 'All Samples' if pd.isna(x) else x)\n",
    "        # print(btret)\n",
    "        # btret.head()\n",
    "    else:\n",
    "        btret = pd.read_csv(dataset, low_memory=False)\n",
    "        \n",
    "#     # Take genes who had a adjusted p-value is <= 0.01\n",
    "#     grouped = []\n",
    "#     for stage, gdf in btret.groupby('Stage2'):\n",
    "#         print(stage)\n",
    "#         print(gdf[gdf['gene']=='KRAS'][statistic].min())\n",
    "\n",
    "#         genesthatpass = gdf[gdf[statistic]<=0.05]['gene'].unique().tolist()\n",
    "#         gdf = gdf[gdf['gene'].isin(genesthatpass)]\n",
    "#         grouped.append(gdf)\n",
    "#     passing_df = pd.concat(grouped, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    passing_df = btret[btret['gene'].isin( btret[btret[statistic]<=0.05]['gene'].unique().tolist() )]\n",
    "    \n",
    "    # This reduces the reference category (refcat) in the bT model\n",
    "    passing_df = passing_df.groupby([\"gene\", bootstrap_method, \"Stage2\"])['Estimate'].median().reset_index(drop=False)\n",
    "    \n",
    "    # Assign percentile rank\n",
    "    ret = []\n",
    "    for g, gdf in passing_df.groupby(['Stage2', bootstrap_method]):\n",
    "        # print(gdf['gene'].shape, gdf['gene'].unique().shape)\n",
    "        gdf['Rank_Order'] = gdf['Estimate'].rank(ascending=False, pct=True)\n",
    "        ret.append(gdf)\n",
    "    ranked_df = pd.concat(ret, axis=0).reset_index(drop=True)\n",
    "    print(ranked_df)\n",
    "    combined_datasets.append(ranked_df)\n",
    "    \n",
    "    if dataset == '':\n",
    "        dataset = 'HTAN'\n",
    "    ranked_df['dataset'] = dataset.replace('/','')\n",
    "\n",
    "    fig, axs = plt.subplots(ranked_df['Stage2'].unique().shape[0], 1, figsize=(16,10))\n",
    "    \n",
    "    i = 0\n",
    "    for g, gdf in ranked_df.groupby(\"Stage2\"):\n",
    "        print(gdf)\n",
    "        mean_rank = gdf.groupby(\"gene\")[\"Rank_Order\"].mean().reset_index(drop=False)\n",
    "        ordered_genes = mean_rank.sort_values(\"Rank_Order\")['gene'].tolist()\n",
    "        plot_order = pd.CategoricalDtype(ordered_genes, ordered=True)\n",
    "        gdf['gene'] = gdf['gene'].astype(plot_order)\n",
    "        # gdf = gdf.sort_values(\"Rank_Order\")\n",
    "        \n",
    "        ybreaks = [0.3, 0.6,] # [0, 0.25, 0.5, .75, 1.0]\n",
    "        # for pos in ybreaks:\n",
    "        #     axs[i].axhline(pos, zorder=0, linestyle='--', color=\"black\", alpha=0.2)\n",
    "\n",
    "        plot = sns.boxplot(x='gene', y='Rank_Order', data=gdf, ax = axs[i], fliersize=0)\n",
    "        # axs[i].scatter(gdf['gene'], gdf['Rank_Order'])\n",
    "        axs[i].tick_params(labelrotation=90, axis='x')\n",
    "        axs[i].set_title(g)\n",
    "        axs[i].set_ylabel(\"Rank Order Percent\")\n",
    "        axs[i].set_yticks([0, 0.3, 0.6, 1.0])\n",
    "        i+=1\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"boxplots_{dataset_names[dataidx]}_{outname}.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "ranked_df = pd.concat(combined_datasets, axis=0).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
