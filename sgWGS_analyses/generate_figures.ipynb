{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaf_thres = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from Bio import AlignIO\n",
    "from sgutils import (\n",
    "    COLUMN_NAMES,\n",
    "    data_factory, polyp_factory, SampleSet,\n",
    "    get_all_queries,\n",
    "    apply_filters, size_filter, coverage_filter,\n",
    "    plot_tree, annotate_tree_with_targets,\n",
    "    df_filter_targets, load_driver_genes,\n",
    "    plot_cmpr_pars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from itables import show as itables_show\n",
    "ishow = partial(itables_show, column_filters = \"footer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyranges as pr\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.concat(\n",
    "    [\n",
    "        pd.read_json(f\"output/FAP01_model_results_vaf-{vaf_thres}.json\"),\n",
    "        pd.read_json(f\"output/FAP03_model_results_vaf-{vaf_thres}.json\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_mixture_filter(query):\n",
    "    if query not in model_results.columns:\n",
    "        raise ValueError(f\"{query} not in model_results\")\n",
    "    if \"_N\" in query:\n",
    "        return True\n",
    "    else:\n",
    "        return model_results[query].is_clonal_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = get_all_queries()\n",
    "tbl = data_factory(\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load blacklist\n",
    "blacklist = pd.read_table(\"./data/sgWGS_black_list.txt\", header=None, names=[\"sample_id\"])\n",
    "blacklist_set = set(blacklist[\"sample_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree(query):\n",
    "    prefixes, col_prefixes, colors = polyp_factory(query, with_normal=True)\n",
    "    store = SampleSet(apply_filters(tbl, vaf_thres=vaf_thres), prefixes)\n",
    "    store.set_colordict(col_prefixes, colors)\n",
    "\n",
    "    # Filter out blacklisted samples\n",
    "    store.sample_df = store.sample_df.query('~Tumor_Sample_Barcode.isin(@blacklist_set)')\n",
    "\n",
    "    # Unfiltered trees\n",
    "    #store.set_alignment_type('binary')\n",
    "    #tree = store.seq_nj_tree()\n",
    "    #store.set_alignment_type('vaf')\n",
    "    #tree = store.seq_nj_tree()\n",
    "\n",
    "    ids = store.sample_df.Tumor_Sample_Barcode.unique()\n",
    "    keep = ids[np.array([clone_mixture_filter(id) for id in ids])]\n",
    "    store.sample_df = store.sample_df.query('Tumor_Sample_Barcode.isin(@keep)')\n",
    "    store.reset_alignments()\n",
    "\n",
    "    # Filtered trees\n",
    "    #store.set_alignment_type('binary')\n",
    "    #tree = store.seq_nj_tree()\n",
    "    store.set_alignment_type('vaf')\n",
    "    tree = store.seq_nj_tree()\n",
    "    return tree, store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAP03_P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"FAP03_P2\"\n",
    "tree, store = get_tree(query)\n",
    "stores[query] = store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    1, 1, figsize=(5, (int(np.floor(store.get_dims()[-1] / 3)) + 2)))\n",
    "\n",
    "plot_tree(tree, store.colordict, ax)\n",
    "annotate_tree_with_targets(tree, ax, store.sample_df)\n",
    "if save_plots:\n",
    "    plt.savefig(f\"figures/{query}_tree_vaf-{vaf_thres}.pdf\")\n",
    "    for record in store.alignment:\n",
    "        record.description = \"\"\n",
    "    with open(f\"output/{query}_align_vaf-{vaf_thres}.fasta\", \"w\") as output_handle:\n",
    "        AlignIO.write(store.alignment, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAP01_T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"FAP01_T3\"\n",
    "tree, store = get_tree(query)\n",
    "stores[query] = store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    1, 1, figsize=(9, (int(np.floor(store.get_dims()[-1] / 3)) + 3)))\n",
    "\n",
    "plot_tree(tree, store.colordict, ax)\n",
    "annotate_tree_with_targets(tree, ax, store.sample_df)\n",
    "if save_plots:\n",
    "    plt.savefig(f\"figures/{query}_tree_vaf-{vaf_thres}.pdf\")\n",
    "    for record in store.alignment:\n",
    "        record.description = \"\"\n",
    "    with open(f\"output/{query}_align_vaf-{vaf_thres}.fasta\", \"w\") as output_handle:\n",
    "        AlignIO.write(store.alignment, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining samples that passed filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = (\n",
    "    model_results.T.reset_index()\n",
    "    .query('~index.str.contains(\"_N\")')\n",
    "    .assign(\n",
    "        sample_name=lambda df: df['index'].str.split('_').str[:2].str.join('_'),\n",
    "        blacklisted=lambda df: df['index'].isin(blacklist_set),\n",
    "        clonal_and_not_blacklisted=lambda df: df['is_clonal_truncated'] & ~df['blacklisted']\n",
    "    )\n",
    "    .groupby('sample_name')\n",
    "    .agg(\n",
    "        total_samples=('index', 'size'),\n",
    "        clonal_samples=('clonal_and_not_blacklisted', 'sum')\n",
    "    )\n",
    "    .assign(\n",
    "        clonal_fraction=lambda df: (df['clonal_samples'] / df['total_samples']).astype(float).round(2)\n",
    "    )\n",
    "    .query('clonal_fraction >= 0.5')\n",
    "    .query('clonal_samples >= 5')\n",
    "    .query('~sample_name.isin([\"FAP03_P2\", \"FAP01_T3\"])')\n",
    ")\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in tqdm(filtered.index):\n",
    "    tree, store = get_tree(query)\n",
    "#    tree.ladderize(reverse=True)\n",
    "    stores[query] = store\n",
    "    fig, ax = plt.subplots(\n",
    "    1, 1, figsize=(7, (int(np.floor(store.get_dims()[-1] / 3)) + 2)))\n",
    "\n",
    "    plot_tree(tree, store.colordict, ax)\n",
    "    annotate_tree_with_targets(tree, ax, store.sample_df)\n",
    "    ax.set_title(query)\n",
    "    if save_plots:\n",
    "        plt.savefig(f\"figures/{query}_tree_vaf-{vaf_thres}.pdf\")\n",
    "        for record in store.alignment:\n",
    "            record.description = \"\"\n",
    "        with open(f\"output/{query}_align_vaf-{vaf_thres}.fasta\", \"w\") as output_handle:\n",
    "            AlignIO.write(store.alignment, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed sample-level data\n",
    "sample_data = (\n",
    "    model_results.T.reset_index()\n",
    "    .query('~index.str.contains(\"_N\")')\n",
    "    .assign(\n",
    "        sample_name=lambda df: df['index'].str.split('_').str[:2].str.join('_'),\n",
    "        blacklisted=lambda df: df['index'].isin(blacklist_set),\n",
    "        sample_group=lambda df: df['index'].str.split('_').str[:2].str.join('_').map(lambda x: \n",
    "            'FAP03_P2' if x == 'FAP03_P2' else\n",
    "            'FAP01_T3' if x == 'FAP01_T3' else\n",
    "            'Filtered' if x in filtered.index else\n",
    "            'Other'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Basic overall summary\n",
    "total_samples = len(sample_data)\n",
    "clonal_samples = sample_data['is_clonal_truncated'].sum()\n",
    "non_clonal_samples = total_samples - clonal_samples\n",
    "blacklisted_samples = sample_data['blacklisted'].sum()\n",
    "\n",
    "print(\"Overall summary:\")\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Clonal samples: {clonal_samples}\")\n",
    "print(f\"Non-clonal samples: {non_clonal_samples}\")\n",
    "print(f\"Blacklisted samples: {blacklisted_samples}\")\n",
    "\n",
    "# Create cross-tabulation of clonal vs blacklisted status\n",
    "sample_data['status'] = (\n",
    "    sample_data['is_clonal_truncated'].map(lambda x: 'clonal' if x else 'not_clonal') + \n",
    "    ' & ' + \n",
    "    sample_data['blacklisted'].map(lambda x: 'blacklisted' if x else 'not_blacklisted')\n",
    ")\n",
    "\n",
    "print(\"\\nCross-tabulation (clonal vs blacklisted):\")\n",
    "overall_crosstab = sample_data['status'].value_counts().sort_index()\n",
    "display(overall_crosstab)\n",
    "\n",
    "print(\"\\nBreakdown by sample group:\")\n",
    "group_crosstab = sample_data.groupby('sample_group')['status'].value_counts().unstack(fill_value=0)\n",
    "display(group_crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsimony comparison for supplement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_plots:\n",
    "    for query, store in stores.items():\n",
    "        print(query)\n",
    "        plot_cmpr_pars(store)\n",
    "        plt.savefig(f\"figures/suppl/{query}_cmpr_pars.pdf\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Rescued Drivers and CNVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_coordinates(hugo_symbol):\n",
    "    \"\"\"Get chromosome, start, and end coordinates for a gene\"\"\"\n",
    "    server = \"https://rest.ensembl.org\"\n",
    "    ext = f\"/lookup/symbol/human/{hugo_symbol}?content-type=application/json\"\n",
    "    \n",
    "    response = requests.get(server + ext)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return (\n",
    "            \"chr\" + data.get('seq_region_name'),\n",
    "            data.get('start'),\n",
    "            data.get('end')\n",
    "        )\n",
    "    return None\n",
    "\n",
    "def get_gene_coords_df(genes):\n",
    "    \"\"\"One-liner version that returns DataFrame\"\"\"\n",
    "    return pd.DataFrame([\n",
    "        {'gene': g, **dict(zip(['Chromosome', 'Start', 'End'], \n",
    "                              get_gene_coordinates(g) or (None, None, None)))}\n",
    "        for g in genes\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_locations = get_gene_coords_df(load_driver_genes().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_fap1 = \"./data/v2/FAP01.all_maf_v2.txt\"\n",
    "fn_fap3 = \"./data/v2/FAP03.all_maf_v2.txt\"\n",
    "\n",
    "fn_fap1_cnv = \"./data/v2/FAP01_sgWGS_cnv_v2.bed\"\n",
    "fn_fap3_cnv = \"./data/v2/FAP03_sgWGS_cnv_v2.bed\"\n",
    "\n",
    "v2_maf = pd.concat(\n",
    "    (\n",
    "        pd.read_table(fn_fap3, low_memory=False),\n",
    "        pd.read_table(fn_fap1, low_memory=False),\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "v2_cnv = pd.concat(\n",
    "    (\n",
    "        pd.read_table(fn_fap3_cnv),\n",
    "        pd.read_table(fn_fap1_cnv),\n",
    "    )\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_pr = pr.PyRanges(gene_locations)\n",
    "\n",
    "def combine_cnv_mutations(custom_annot):\n",
    "    return (\n",
    "        custom_annot\n",
    "        .assign(gene=lambda df: df.mut_str.str.split(\":\").str[0])\n",
    "        .assign(mut=lambda df: df.mut_str.str.split(\":\").str[1])\n",
    "        .groupby([\"Tumor_Sample_Barcode\", \"mut\", \"source\"])\n",
    "        .apply(lambda group: \",\".join(group.gene))\n",
    "        .reset_index(name=\"genes\")\n",
    "        .assign(mut_str=lambda df: df.genes + \":\" + df.mut)\n",
    "    )\n",
    "\n",
    "def get_cnv_overlaps(v2_cnv, samples, gene_pr):\n",
    "    cnv_pr = pr.PyRanges(v2_cnv\n",
    "        .query(\"id.isin(@samples)\")\n",
    "        .assign(Chromosome=lambda df: \"chr\" + df.chromosome.astype(str))\n",
    "        .rename(columns={'start.pos': 'Start', 'end.pos': 'End'})\n",
    "    )\n",
    "\n",
    "    cnv_gene_overlaps = cnv_pr.join(gene_pr)\n",
    "    return cnv_gene_overlaps\n",
    "\n",
    "def get_cnv_annot(v2_cnv, samples, gene_pr):\n",
    "    cnv_gene_overlaps = get_cnv_overlaps(v2_cnv, samples, gene_pr)\n",
    "\n",
    "    cnv_annot = pd.concat((\n",
    "        (\n",
    "            cnv_gene_overlaps.as_df().query(\"(`CNt.adj` == 2) & (`A.adj` != 1) & (`Bf` <= 0.2)\")\n",
    "            .rename(columns={\"id\": \"Tumor_Sample_Barcode\"})\n",
    "            .assign(mut_str=lambda df: df['gene'] + \":LOH\")\n",
    "            .assign(source=\"cnv\")\n",
    "            [['Tumor_Sample_Barcode', 'mut_str', 'source']]\n",
    "        ),\n",
    "        (\n",
    "            cnv_gene_overlaps.as_df().query(\"(`CNt.adj` < 2)\")\n",
    "            .rename(columns={\"id\": \"Tumor_Sample_Barcode\"})\n",
    "            .assign(mut_str=lambda df: df['gene'] + \":DEL\")\n",
    "            .assign(source=\"cnv\")\n",
    "            [['Tumor_Sample_Barcode', 'mut_str', 'source']]\n",
    "        ),\n",
    "        (\n",
    "            cnv_gene_overlaps.as_df().query(\"(`CNt.adj` > 2)\")\n",
    "            .rename(columns={\"id\": \"Tumor_Sample_Barcode\"})\n",
    "            .assign(mut_str=lambda df: df['gene'] + \":AMP\")\n",
    "            .assign(source=\"cnv\")\n",
    "            [['Tumor_Sample_Barcode', 'mut_str', 'source']]\n",
    "        ),\n",
    "    ))\n",
    "    return cnv_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longer_mutations_annot(samples):\n",
    "    genes = load_driver_genes()\n",
    "\n",
    "    missing = (\n",
    "        tbl\n",
    "        .query(\"Tumor_Sample_Barcode.isin(@samples)\")\n",
    "        .query(\"Hugo_Symbol.isin(@genes)\")\n",
    "        .assign(ref_len=lambda df: df[COLUMN_NAMES['ref_allele']].str.len())\n",
    "        .assign(alt_len=lambda df: df[COLUMN_NAMES['alt_allele']].str.len())\n",
    "        .query('(ref_len != 1) | (alt_len != 1)')\n",
    "        .query(f'{COLUMN_NAMES[\"variant_class\"]}.str.contains(\"Mutation\") | {COLUMN_NAMES[\"variant_class\"]}.str.contains(\"Frame_Shift\")')\n",
    "        [['Tumor_Sample_Barcode', 'Hugo_Symbol', 'ref_len', 'alt_len', COLUMN_NAMES['aa_change'], COLUMN_NAMES['variant_class'], 'VAF', COLUMN_NAMES['total_depth']]]\n",
    "        .assign(mut_str=lambda df: df['Hugo_Symbol'] +\":\"+ df[COLUMN_NAMES['aa_change']])\n",
    "        .assign(source='longer')\n",
    "        [['Tumor_Sample_Barcode', 'mut_str', 'source']]\n",
    "\n",
    "    )\n",
    "\n",
    "    if len(missing) > 0:\n",
    "        return missing\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_v2_tbl(v2_tbl, store_tbl):\n",
    "    key_cols = ['Chromosome', 'Start_Position', 'End_Position', 'Hugo_Symbol']\n",
    "\n",
    "    v2_tbl_copy = v2_tbl.copy()\n",
    "    store_tbl_copy = store_tbl.copy()\n",
    "\n",
    "    v2_tbl_copy['location_key'] = v2_tbl_copy[key_cols].apply(lambda x: tuple(x), axis=1)\n",
    "    store_tbl_copy['location_key'] = store_tbl_copy[key_cols].apply(lambda x: tuple(x), axis=1)\n",
    "\n",
    "    store_tbl_locations = set(store_tbl_copy['location_key'])\n",
    "    store_tbl_full_keys = set(store_tbl_copy.apply(lambda x: (x['location_key'], x['Tumor_Sample_Barcode']), axis=1))\n",
    "    mask = (\n",
    "        v2_tbl_copy['location_key'].isin(store_tbl_locations) &  # Location exists in store_tbl\n",
    "        ~v2_tbl_copy.apply(lambda x: (x['location_key'], x['Tumor_Sample_Barcode']), axis=1).isin(store_tbl_full_keys)  # But full combo doesn't\n",
    "    )\n",
    "\n",
    "    result = v2_tbl_copy[mask].copy()\n",
    "    store_tbl_mut_str_map = store_tbl_copy.groupby('location_key')['mut_str'].first().to_dict()\n",
    "    result['mut_str'] = result['location_key'].map(store_tbl_mut_str_map)\n",
    "    result = result.drop('location_key', axis=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_v2_muts(v2_maf, annot_df, samples, genes):\n",
    "    v2_tbl = (\n",
    "        v2_maf.query(\"Tumor_Sample_Barcode.isin(@samples)\")\n",
    "        .query(\"Hugo_Symbol.isin(@genes)\")[\n",
    "            [\n",
    "                \"Chromosome\",\n",
    "                \"Start_Position\",\n",
    "                \"End_Position\",\n",
    "                \"Hugo_Symbol\",\n",
    "                \"aaChange\",\n",
    "                \"Tumor_Sample_Barcode\",\n",
    "                \"Total_allele_depth\",\n",
    "                \"VAF\",\n",
    "            ]\n",
    "        ]\n",
    "        .sort_values(by=[\"Hugo_Symbol\", \"Total_allele_depth\"], ascending=False)\n",
    "    )\n",
    "\n",
    "    store_tbl = annot_df[\n",
    "        [\n",
    "            \"Chromosome\",\n",
    "            \"Start_Position\",\n",
    "            \"End_Position\",\n",
    "            COLUMN_NAMES[\"sample_id\"],\n",
    "            COLUMN_NAMES[\"gene\"],\n",
    "            COLUMN_NAMES[\"aa_change\"],\n",
    "            COLUMN_NAMES[\"total_depth\"],\n",
    "            \"VAF\",\n",
    "            \"mut_str\",\n",
    "        ]\n",
    "    ].sort_values([COLUMN_NAMES[\"gene\"], COLUMN_NAMES[\"total_depth\"]], ascending=False)\n",
    "    v2_tbl_filtered = filter_v2_tbl(v2_tbl, store_tbl)\n",
    "    return v2_tbl_filtered\n",
    "\n",
    "def add_custom_annot(tree, ax, annot_df, fontsize=8):\n",
    "    source_colors = {\n",
    "        'cnv': 'black',\n",
    "        'store': 'black',\n",
    "        'v2': 'gray',\n",
    "        'longer': 'black',\n",
    "    }\n",
    "\n",
    "    def combine_mutations(group):\n",
    "        return list(zip(group['mut_str'], group['source']))\n",
    "    \n",
    "    annot_dict = annot_df.groupby(COLUMN_NAMES['sample_id']).apply(combine_mutations).to_dict()\n",
    "    \n",
    "    text_labels = [text for text in ax.get_children() if isinstance(text, plt.Text)]\n",
    "    for text in text_labels:\n",
    "        leaf_label = text.get_text().strip()\n",
    "        if leaf_label in annot_dict:\n",
    "            x, y = text.get_position()\n",
    "            x = x - tree.find_any(name=leaf_label).branch_length\n",
    "            pixel_x, pixel_y = ax.transData.transform((x, y))\n",
    "            pixel_x_offset = pixel_x + 5\n",
    "            \n",
    "            # Get list of (mutation, source) tuples for this sample\n",
    "            mut_source_pairs = annot_dict[leaf_label]\n",
    "            \n",
    "            # Plot each line with appropriate color based on its source\n",
    "            for i, (mut_str, source) in enumerate(mut_source_pairs):\n",
    "                # Get color for this source, default to black if not found\n",
    "                color = source_colors.get(source, 'black')\n",
    "                \n",
    "                # Convert data coordinates to pixel coordinates\n",
    "                pixel_y_offset = pixel_y + 2 + (i * 15)\n",
    "                x_offset, y_offset = ax.transData.inverted().transform((pixel_x_offset, pixel_y_offset))\n",
    "                \n",
    "                ax.text(x_offset, y_offset, mut_str, fontsize=fontsize, \n",
    "                       verticalalignment='bottom', color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Trees with additional Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_dict = {\n",
    "    'FAP03_P2': (5, 12),\n",
    "    'FAP01_T3': (8, 12),\n",
    "    'FAP01_P6': (8, 8),\n",
    "    'FAP03_P1': (8, 5),\n",
    "}\n",
    "\n",
    "all_annots = []\n",
    "all_samples = []\n",
    "for query, store in stores.items():\n",
    "    annot_df = df_filter_targets(store.sample_df)\n",
    "    genes = annot_df.Hugo_Symbol.unique()\n",
    "    samples = store.sample_df.Tumor_Sample_Barcode.unique()\n",
    "\n",
    "    tree = store.seq_nj_tree()\n",
    "    samples = [term.name for term in tree.get_terminals() if term.name in samples]\n",
    "\n",
    "    v2_annot = get_v2_muts(v2_maf, annot_df, samples, genes)\n",
    "\n",
    "    custom_annot = pd.concat((\n",
    "        annot_df[['Tumor_Sample_Barcode', 'mut_str']].assign(source='store'),\n",
    "        v2_annot[['Tumor_Sample_Barcode', 'mut_str']].assign(source='v2'),\n",
    "        get_cnv_annot(v2_cnv, samples, gene_pr)\n",
    "    ))\n",
    "\n",
    "    longer_annot = get_longer_mutations_annot(samples)\n",
    "    if longer_annot is not None:\n",
    "        custom_annot = pd.concat((custom_annot, longer_annot))\n",
    "\n",
    "    all_annots.append(custom_annot)\n",
    "    all_samples.extend([sample for sample in samples if not \"_N\" in sample])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=dim_dict[query])\n",
    "\n",
    "    plot_tree(tree, store.colordict, ax)\n",
    "    for label in ax.texts:\n",
    "        label.set_fontsize(16)\n",
    "#    add_custom_annot(tree, ax, custom_annot)\n",
    "    add_custom_annot(tree, ax, combine_cnv_mutations(custom_annot))\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig(f\"figures/{query}_tree_vaf-{vaf_thres}_full-annot.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More on driver rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"FAP01_T3\"\n",
    "#query = \"FAP03_P1\"\n",
    "store = stores[query]\n",
    "\n",
    "annot_df = df_filter_targets(store.sample_df)\n",
    "genes = annot_df.Hugo_Symbol.unique()\n",
    "samples = store.sample_df.query(\"~Tumor_Sample_Barcode.str.contains('_N')\").Tumor_Sample_Barcode.unique()\n",
    "\n",
    "v2_annot = get_v2_muts(v2_maf, annot_df, samples, genes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = (\n",
    "    pd.concat(\n",
    "        (\n",
    "            annot_df[\n",
    "                [\n",
    "                    COLUMN_NAMES[\"sample_id\"],\n",
    "                    COLUMN_NAMES[\"total_depth\"],\n",
    "                    COLUMN_NAMES[\"gene\"],\n",
    "                    \"mut_str\",\n",
    "                ]\n",
    "            ]\n",
    "            .assign(source=\"store\")\n",
    "            .rename(columns={COLUMN_NAMES[\"total_depth\"]: \"Total_allele_depth\"}),\n",
    "            v2_annot[\n",
    "                [\"Tumor_Sample_Barcode\", \"Total_allele_depth\", \"Hugo_Symbol\", \"mut_str\"]\n",
    "            ].assign(source=\"v2\"),\n",
    "        )\n",
    "    )\n",
    "    .sort_values(by=[\"Hugo_Symbol\", \"Total_allele_depth\"], ascending=False)\n",
    "    .query(\"Hugo_Symbol != 'CTNNB1'\")\n",
    ")\n",
    "\n",
    "bins = 50\n",
    "alpha = 0.7\n",
    "\n",
    "# Calculate grid dimensions\n",
    "n_samples = len(samples)\n",
    "n_cols = min(4, n_samples)\n",
    "n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "if n_samples == 1:\n",
    "    axes = [axes]\n",
    "elif n_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes_flat = axes.flatten() if n_samples > 1 else axes\n",
    "\n",
    "# Create color map for Hugo_Symbols, but force APC to red and SMAD4 to orange\n",
    "unique_genes = drivers['Hugo_Symbol'].unique()\n",
    "gene_colors = {}\n",
    "for gene in unique_genes:\n",
    "    if gene == \"APC\":\n",
    "        gene_colors[gene] = \"red\"\n",
    "    elif gene == \"SMAD4\":\n",
    "        gene_colors[gene] = \"orange\"\n",
    "    else:\n",
    "        # Use Set1 colormap for other genes, skipping first two colors (red, orange)\n",
    "        # so as not to duplicate APC/SMAD4\n",
    "        # Find the index of this gene among the non-APC/SMAD4 genes\n",
    "        other_genes = [g for g in unique_genes if g not in (\"APC\", \"SMAD4\")]\n",
    "        color_idx = other_genes.index(gene) if gene in other_genes else 0\n",
    "        # Set1 has 9 colors, skip 0 (red) and 1 (orange)\n",
    "        cmap = plt.cm.Set1\n",
    "        # Use color_idx+2 to skip red/orange, wrap around if needed\n",
    "        color = cmap((color_idx + 2) / max(3, len(other_genes) + 2))\n",
    "        gene_colors[gene] = color\n",
    "\n",
    "for i, sample_name in enumerate(sorted(samples)):\n",
    "    ax = axes_flat[i]\n",
    "    \n",
    "    # Subset data for this sample\n",
    "    data = store.sample_df.query(\"Tumor_Sample_Barcode == @sample_name\")\n",
    "    \n",
    "    title = sample_name\n",
    "    title_color = 'black'\n",
    "\n",
    "    coverage = data[COLUMN_NAMES['total_depth']]\n",
    "    ax.hist(coverage, bins=bins, alpha=alpha, edgecolor='black', linewidth=0.5)\n",
    "    ax.set_xlabel('Total Depth')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(title, color=title_color)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(left=0)\n",
    "\n",
    "    # Add vertical lines for driver mutations in this sample\n",
    "    sample_drivers = drivers.query(\"Tumor_Sample_Barcode == @sample_name\")\n",
    "    for _, row in sample_drivers.iterrows():\n",
    "        gene = row['Hugo_Symbol']\n",
    "        depth = row['Total_allele_depth']\n",
    "        color = gene_colors[gene]\n",
    "        ax.axvline(x=depth, color=color, linestyle='--', linewidth=2, alpha=0.8, label=gene)\n",
    "\n",
    "    # Add statistics\n",
    "    mean_cov = coverage.mean()\n",
    "    median_cov = coverage.median()\n",
    "    n_variants = len(coverage)\n",
    "\n",
    "    stats_text = f'n={n_variants}\\nMean: {mean_cov:.1f}x\\nMedian: {median_cov:.1f}x'\n",
    "    ax.text(0.7, 0.8, stats_text, transform=ax.transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "            verticalalignment='top')\n",
    "\n",
    "    # Add legend if there are driver mutations for this sample\n",
    "    if len(sample_drivers) > 0:\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(0.95, 0.5))\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(n_samples, len(axes_flat)):\n",
    "    axes_flat[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(f\"figures/{query}_driver_rescue_coverage.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers.query(\"Hugo_Symbol == 'APC'\").sort_values('Tumor_Sample_Barcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apc_depth_path = Path(\"./data/apc_depth/\")\n",
    "\n",
    "apc_depth_files = [fn for fn in (sorted(apc_depth_path.glob(\"*.txt\"))) if fn.name.startswith(f\"{query}_R\") and fn.stem.replace(\".apc_depth\", \"\") in samples]\n",
    "apc_depth_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apc_var = (\n",
    "    annot_df.query(\"Hugo_Symbol == 'APC'\")[\n",
    "        [\"Start_Position\", \"End_Position\", \"Variant_Type\"]\n",
    "    ]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "assert len(apc_var) == 1\n",
    "apc_var = apc_var.squeeze()\n",
    "if apc_var.Variant_Type == \"DEL\":\n",
    "    apc_loc = apc_var.Start_Position - 1\n",
    "else:\n",
    "    apc_loc = apc_var.Start_Position\n",
    "\n",
    "# Subset drivers to only APC\n",
    "apc_drivers = drivers.query(\"Hugo_Symbol == 'APC'\")\n",
    "\n",
    "# Set up for two columns\n",
    "n_files = len(apc_depth_files)\n",
    "n_cols = 2\n",
    "n_rows = (n_files + n_cols - 1) // n_cols  # ceiling division\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 2 * n_rows), sharex=True)\n",
    "axes = np.array(axes).reshape(-1, n_cols)  # Ensure axes is always 2D\n",
    "\n",
    "for i, fn in enumerate(apc_depth_files):\n",
    "    depth_df = pd.read_table(fn, names=[\"chr\", \"pos\", \"depth\"])\n",
    "    stride = max(1, len(depth_df) // 10000)  # target ~10,000 points max\n",
    "    plot_df = depth_df.iloc[::stride, :]\n",
    "\n",
    "    # Remove the .apc_depth suffix to get the sample name\n",
    "    sample_name = fn.stem.replace(\".apc_depth\", \"\")\n",
    "\n",
    "    # Grab the coverage at the APC locus, if present\n",
    "    apc_cov_row = depth_df[depth_df[\"pos\"] == apc_loc]\n",
    "    if not apc_cov_row.empty:\n",
    "        apc_cov = apc_cov_row[\"depth\"].iloc[0]\n",
    "        apc_cov_str = f\"APC@{apc_loc}: {apc_cov}x\"\n",
    "    else:\n",
    "        apc_cov = None\n",
    "        apc_cov_str = f\"APC@{apc_loc}: N/A\"\n",
    "\n",
    "    # Check if sample is in APC drivers\n",
    "    driver_row = apc_drivers[apc_drivers[\"Tumor_Sample_Barcode\"] == sample_name]\n",
    "    if not driver_row.empty:\n",
    "        # Get source if present\n",
    "        source = driver_row[\"source\"].iloc[0] if \"source\" in driver_row.columns else None\n",
    "        if source == \"store\":\n",
    "            title_color = \"green\"\n",
    "        elif source == \"v2\":\n",
    "            title_color = \"orange\"\n",
    "        else:\n",
    "            title_color = \"gray\"\n",
    "        title_text = f\"{sample_name} ({apc_cov_str})\"\n",
    "    else:\n",
    "        # Not in drivers\n",
    "        title_color = \"red\"\n",
    "        title_text = f\"{sample_name} (absent, {apc_cov_str})\"\n",
    "\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    ax = axes[row, col]\n",
    "    ax.axvline(apc_loc, color='red', linestyle='--', linewidth=1.0, label='mutation')\n",
    "    ax.plot(plot_df[\"pos\"], plot_df[\"depth\"], lw=0.7, color='tab:blue')\n",
    "    ax.set_ylabel(\"Sequencing depth\")\n",
    "    ax.set_title(\n",
    "        f\"Depth across locus for {title_text}\",\n",
    "        color=title_color,\n",
    "    )\n",
    "    ax.set_ylim(bottom=0)  # Set lower ylim to 0\n",
    "    # Optionally, add legend only to the first subplot\n",
    "    if i == 0:\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "# Hide unused subplots if any\n",
    "for j in range(n_files, n_rows * n_cols):\n",
    "    row = j // n_cols\n",
    "    col = j % n_cols\n",
    "    axes[row, col].set_visible(False)\n",
    "\n",
    "# Set xlabel for bottom row\n",
    "for col in range(n_cols):\n",
    "    axes[-1, col].set_xlabel(\"Genomic position (chr5)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(f\"figures/{query}_APC_depth_panel.pdf\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oncoplot-style plots for Driver annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_value = {\n",
    "    'LOH': 1,\n",
    "    'AMP': 2,\n",
    "    'DEL': 3,\n",
    "    'FS': 4,\n",
    "    'STOP': 5,\n",
    "    'MISS': 6\n",
    "}\n",
    "\n",
    "value_to_category = {\n",
    "    v: k for k, v in category_to_value.items()\n",
    "}\n",
    "value_to_category[0] = 'neutral'\n",
    "\n",
    "# colors for value 0, 1, 2, 3, 4, 5, 6\n",
    "category_colors = ['#e0e0e0', '#aed8e6ff', '#ed2224ff', '#3a53a4ff', '#a68027ff', '#707f8fff', '#008001ff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (\n",
    "    pd.concat(all_annots)\n",
    "#    .query(\"source == 'cnv'\")\n",
    "    .assign(gene=lambda df: df.mut_str.str.split(\":\").str[0])\n",
    "    .assign(mut=lambda df: df.mut_str.str.split(\":\").str[1])\n",
    "    .assign(lesion=lambda df: df.Tumor_Sample_Barcode.str.split(\"_\").str[0:2].str.join(\"_\"))\n",
    "    .assign(\n",
    "        variant_pos=lambda df: df.apply(\n",
    "            lambda row: (\n",
    "                int(re.search(r'p\\.[A-Z](\\d+)', row['mut']).group(1))\n",
    "                if (\n",
    "                    row['source'] != 'cnv'\n",
    "                    and isinstance(row['mut'], str)\n",
    "                    and re.search(r'p\\.[A-Z](\\d+)', row['mut'])\n",
    "                ) else -1\n",
    "            ),\n",
    "            axis=1\n",
    "        ).astype(int)\n",
    "    )\n",
    ")\n",
    "\n",
    "onco_matrix = (\n",
    "    tmp\n",
    "    .assign(mut=lambda df: df.mut.map(lambda x: x if not \"fs*\" in x else \"FS\"))\n",
    "    .assign(mut=lambda df: df.mut.map(lambda x: x if not \"*\" in x else \"STOP\"))\n",
    "    .assign(mut=lambda df: df.mut.map(lambda x: x if not \"p.\" in x else \"MISS\"))\n",
    "    .assign(mut=lambda df: df.mut.map(category_to_value))\n",
    "    .pivot_table(\n",
    "        index='gene',\n",
    "        columns='Tumor_Sample_Barcode',\n",
    "        values='mut',\n",
    "        aggfunc=lambda x: ( # prioritize STOP, FS, MISS, DEL, AMP, LOH\n",
    "            x[x.isin([5,4,6,3,2,1])].sort_values(key=lambda s: s.map({5:0,4:1,6:2,3:3,2:4,1:5})).iloc[0]\n",
    "            if x.isin([5,4,6,3,2,1]).any() else 0\n",
    "        ),\n",
    "        fill_value=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the rows by number of non-zero values (most non-zeros on top)\n",
    "row_order = onco_matrix.astype(bool).sum(axis=1).sort_values(ascending=False).index\n",
    "onco_matrix_sorted = onco_matrix.loc[row_order]\n",
    "\n",
    "# Desired sample group order\n",
    "desired_group_order = ['FAP01_P6', 'FAP01_T3', 'FAP03_P1', 'FAP03_P2', ]\n",
    "\n",
    "# Ensure all samples in all_samples are present as columns, filling missing ones with 0s\n",
    "missing_samples = [s for s in all_samples if s not in onco_matrix_sorted.columns]\n",
    "for s in missing_samples:\n",
    "    onco_matrix_sorted[s] = 0\n",
    "\n",
    "# Reorder columns: within each group, keep the order from all_samples, but order groups as desired\n",
    "def group_key(sample):\n",
    "    for i, prefix in enumerate(desired_group_order):\n",
    "        if str(sample).startswith(prefix):\n",
    "            return (i, all_samples.index(sample))\n",
    "    # If not matched, put at the end\n",
    "    return (len(desired_group_order), all_samples.index(sample))\n",
    "\n",
    "ordered_samples = sorted(all_samples, key=group_key)\n",
    "onco_matrix_sorted = onco_matrix_sorted[ordered_samples]\n",
    "\n",
    "# --- Annotate APC FS and STOP variants with variant_pos ---\n",
    "onco_matrix_display = onco_matrix_sorted.copy().astype(object)\n",
    "\n",
    "annotations = pd.DataFrame('', index=onco_matrix_display.index, columns=onco_matrix_display.columns)\n",
    "if 'APC' in onco_matrix_display.index:\n",
    "    for col in onco_matrix_display.columns:\n",
    "        cell_val = onco_matrix_display.loc['APC', col]\n",
    "        # 4 = FS, 5 = STOP (see category_to_value)\n",
    "        if cell_val in (4, 5):\n",
    "            # Find mutations that match the displayed mutation type\n",
    "            apc_rows = tmp[(tmp['gene'] == 'APC') & (tmp['Tumor_Sample_Barcode'] == col)]\n",
    "            target_mut_type = \"FS\" if cell_val == 4 else \"STOP\"\n",
    "            \n",
    "            # Filter to mutations that would map to the same category as displayed\n",
    "            matching_rows = apc_rows[\n",
    "                apc_rows['mut'].apply(lambda x: \n",
    "                    (target_mut_type == \"FS\" and \"fs*\" in str(x)) or\n",
    "                    (target_mut_type == \"STOP\" and \"*\" in str(x) and \"fs*\" not in str(x))\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            if not matching_rows.empty:\n",
    "                # Use the first matching mutation's variant_pos\n",
    "                variant_pos = matching_rows.iloc[0]['variant_pos']\n",
    "                if pd.notnull(variant_pos) and variant_pos != -1:\n",
    "                    annotations.loc['APC', col] = str(int(variant_pos))\n",
    "\n",
    "# Identify individuals by sample column prefixes, in the new order\n",
    "individual_prefixes = desired_group_order\n",
    "columns = onco_matrix_display.columns\n",
    "\n",
    "# Find the column indices where a new individual starts (except the first)\n",
    "individual_starts = []\n",
    "for prefix in individual_prefixes:\n",
    "    indices = [i for i, col in enumerate(columns) if str(col).startswith(prefix)]\n",
    "    if indices:\n",
    "        individual_starts.append(indices[0])\n",
    "individual_starts = sorted(set(individual_starts))\n",
    "separator_indices = [i for i in individual_starts if i != 0]\n",
    "\n",
    "# Create a colormap and norm for the heatmap\n",
    "cmap = mpl.colors.ListedColormap(category_colors)\n",
    "bounds = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig_width = 12\n",
    "fig_height = 5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "sns.heatmap(\n",
    "    onco_matrix_sorted,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    cbar=False,\n",
    "    ax=ax,\n",
    "    annot=annotations,\n",
    "    fmt='',\n",
    "    annot_kws={\"fontsize\": 6, \"va\": \"center\", \"ha\": \"center\"}\n",
    ")\n",
    "\n",
    "# Remove axis labels\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "\n",
    "# Set custom x-axis tick labels: show only the suffix after the lesion name (e.g., R5_G1)\n",
    "def get_sample_suffix(sample):\n",
    "    # sample is e.g. FAP01_P6_R5_G1\n",
    "    parts = str(sample).split(\"_\")\n",
    "    if len(parts) > 2:\n",
    "        return \"_\".join(parts[2:])\n",
    "    else:\n",
    "        return str(sample)\n",
    "\n",
    "ax.set_xticks(np.arange(len(onco_matrix_sorted.columns)) + 0.5)\n",
    "ax.set_xticklabels([get_sample_suffix(s) for s in onco_matrix_sorted.columns], rotation=90)\n",
    "\n",
    "# Add vertical separator lines between individuals\n",
    "for idx in separator_indices:\n",
    "    ax.axvline(idx, color='black', linewidth=2)\n",
    "\n",
    "# --- Add lesion/individual names atop the relevant heatmap sections ---\n",
    "# For each group, place the group name centered above its section\n",
    "for prefix in desired_group_order:\n",
    "    # Find all columns for this group\n",
    "    indices = [i for i, col in enumerate(onco_matrix_sorted.columns) if str(col).startswith(prefix)]\n",
    "    if indices:\n",
    "        start = indices[0]\n",
    "        end = indices[-1]\n",
    "        center = (start + end) / 2 + 0.5  # +0.5 to align with heatmap grid\n",
    "        ax.text(\n",
    "            center,\n",
    "            -0.2,  # slightly above the heatmap (tweak as needed)\n",
    "            prefix,\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=12,\n",
    "            fontweight='bold',\n",
    "            transform=ax.transData,\n",
    "            clip_on=False\n",
    "        )\n",
    "\n",
    "# Create custom legend\n",
    "present_values = set(onco_matrix.values.flatten())\n",
    "handles = [\n",
    "    mpl.patches.Patch(color=category_colors[i], label=label)\n",
    "    for i, label in value_to_category.items() if i in present_values\n",
    "]\n",
    "ax.legend(\n",
    "    handles=handles,\n",
    "    title=\"Mutation Type\",\n",
    "    bbox_to_anchor=(1.01, 1),\n",
    "    loc='upper left',\n",
    "    borderaxespad=0.\n",
    ")\n",
    "fig.tight_layout()\n",
    "if save_plots:\n",
    "    fig.savefig('figures/onco_matrix.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation sharing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_sharing(filtered_counts, ax):\n",
    "    sns.barplot(x=filtered_counts.index, y=filtered_counts.values, color=\"steelblue\", ax=ax)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(\"Number of samples sharing mutation\")\n",
    "    ax.set_ylabel(\"Number of mutations\")\n",
    "    ax.set_title(f\"Distribution of filtered mutation sharing across samples (n: {filtered_counts.sum()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_mutation_sharing(filtered_counts, filtered_out_counts, n_samples, ax):\n",
    "    x_positions = range(1, n_samples + 1)\n",
    "    \n",
    "    # Create stacked bars\n",
    "    ax.bar(x_positions, filtered_counts.values, color=\"steelblue\", label=\"Filtered mutations\")\n",
    "    ax.bar(x_positions, filtered_out_counts.values, \n",
    "            bottom=filtered_counts.values, color=\"gray\", label=\"Filtered out mutations\")\n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(\"Number of samples sharing mutation\")\n",
    "    ax.set_ylabel(\"Number of mutations\")\n",
    "    ax.set_title(f\"Distribution of mutation sharing across samples (n: {(filtered_counts + filtered_out_counts).sum()})\")\n",
    "    ax.legend()\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xlim(0.5, n_samples + 0.5)\n",
    "    ax.grid(axis='x', visible=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_mutation_sharing_simple(filtered_counts, filtered_out_counts, n_samples, ax):\n",
    "    x_positions = range(1, n_samples + 1)\n",
    "    \n",
    "    # Create stacked bars\n",
    "    ax.bar(x_positions, filtered_counts.values, color=\"steelblue\", label=\"Filtered mutations\")\n",
    "    ax.bar(x_positions, filtered_out_counts.values, \n",
    "            bottom=filtered_counts.values, color=\"gray\", label=\"Filtered out mutations\")\n",
    "    \n",
    "    ax.set_xlabel(\"Number of samples sharing mutation\")\n",
    "    ax.set_ylabel(\"Number of mutations\")\n",
    "    ax.set_title(f\"Distribution of mutation sharing across samples (n: {(filtered_counts + filtered_out_counts).sum()})\")\n",
    "    ax.legend()\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels([int(x) for x in x_positions])\n",
    "    ax.set_xlim(0.5, n_samples + 0.5)\n",
    "    ax.grid(axis='x', visible=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_broken_axis_mutation_sharing(filtered_counts, filtered_out_counts, n_samples, ax1, ax2, split_point=325):\n",
    "    x_positions = range(1, n_samples + 1)\n",
    "    total_counts = filtered_counts + filtered_out_counts\n",
    "\n",
    "    # Upper subplot (high values) - log scale\n",
    "    ax1.bar(x_positions, filtered_counts.values, color=\"steelblue\", label=\"Filtered mutations\")\n",
    "    ax1.bar(x_positions, filtered_out_counts.values, \n",
    "            bottom=filtered_counts.values, color=\"gray\", label=\"Filtered out mutations\")\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_ylim(bottom=split_point)  # Focus on the high values, let matplotlib auto-scale the top\n",
    "    ax1.set_ylabel(\"\")\n",
    "    ax1.legend()\n",
    "    ax1.set_xticks(x_positions)\n",
    "    ax1.set_xlim(0.5, n_samples + 0.5)\n",
    "    ax1.grid(axis='x', visible=False)\n",
    "\n",
    "    # Lower subplot (low values)\n",
    "    ax2.bar(x_positions, filtered_counts.values, color=\"steelblue\")\n",
    "    ax2.bar(x_positions, filtered_out_counts.values, \n",
    "            bottom=filtered_counts.values, color=\"gray\")\n",
    "    ax2.set_ylim(0, split_point)  # Focus on the lower values\n",
    "    ax2.set_xlabel(\"Number of samples sharing mutation\")\n",
    "    ax2.set_ylabel(\"Number of mutations\")\n",
    "    ax2.set_xticks(x_positions)\n",
    "    ax2.set_xlim(0.5, n_samples + 0.5)\n",
    "    ax2.grid(axis='x', visible=False)\n",
    "\n",
    "    # Add break marks\n",
    "    ax1.spines['bottom'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax1.tick_params(labeltop=False, bottom=False, labelbottom=False)\n",
    "    ax2.xaxis.tick_bottom()\n",
    "\n",
    "    # Add diagonal lines to indicate the break\n",
    "    d = 0.015  # size of diagonal lines\n",
    "    kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)\n",
    "    ax1.plot((-d, +d), (-d, +d), **kwargs)\n",
    "    ax1.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "\n",
    "    kwargs.update(transform=ax2.transAxes)\n",
    "    ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "    ax2.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "    ax1.set_title(f\"Distribution of mutation sharing across samples (n: {total_counts.sum()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_sharing_comparison(filtered_counts, filtered_out_counts, n_samples, split_point):\n",
    "    # Create figure with 4 panels comparing different plotting approaches\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    gs = fig.add_gridspec(2, 2, height_ratios=[1, 1], hspace=0.3, wspace=0.2)\n",
    "\n",
    "    # Panel 1: Standard bar plot\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    plot_mutation_sharing(filtered_counts, ax1)\n",
    "\n",
    "    # Panel 2: Simple stacked plot\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    plot_stacked_mutation_sharing_simple(filtered_counts, filtered_out_counts, n_samples, ax2)\n",
    "\n",
    "    # Panel 3: Stacked plot with log scale\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    plot_stacked_mutation_sharing(filtered_counts, filtered_out_counts, n_samples, ax3)\n",
    "\n",
    "    # Panel 4: Broken axis plot - create vertically stacked subplots with minimal space between them\n",
    "    gs_broken = gs[1, 1].subgridspec(2, 1, height_ratios=[1, 1], hspace=0.05)\n",
    "    ax4_top = fig.add_subplot(gs_broken[0])\n",
    "    ax4_bottom = fig.add_subplot(gs_broken[1], sharex=ax4_top)\n",
    "    plot_broken_axis_mutation_sharing(filtered_counts, filtered_out_counts, n_samples, ax4_top, ax4_bottom, split_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_points = {\n",
    "    'FAP03_P2': 325,\n",
    "    'FAP01_T3': 2100,\n",
    "    'FAP01_P6': 3300,\n",
    "    'FAP03_P1': 1600,\n",
    "}\n",
    "\n",
    "for query, store in stores.items():\n",
    "    print(query)\n",
    "\n",
    "    query_str = \"~Tumor_Sample_Barcode.str.contains('_N')\"\n",
    "    input_df = store.sample_df.query(query_str).copy()\n",
    "\n",
    "    samples = input_df.Tumor_Sample_Barcode.unique()\n",
    "    unfiltered_input_df = tbl.query('Tumor_Sample_Barcode in @samples').copy()\n",
    "\n",
    "    n_samples = len(samples)\n",
    "\n",
    "    # Calculate mutation sharing counts for both datasets\n",
    "    def get_mutation_sharing_counts(df, n_samples):\n",
    "        return (\n",
    "            df\n",
    "            .pivot_table(\n",
    "                index=store.var_cols,\n",
    "                columns=store.sample_col,\n",
    "                values='VAF',\n",
    "                aggfunc=lambda x: 1,\n",
    "                fill_value=0\n",
    "            )\n",
    "            .sum(axis=1)\n",
    "            .value_counts()\n",
    "            .reindex(range(1, n_samples + 1), fill_value=0)\n",
    "            .sort_index()\n",
    "        )\n",
    "\n",
    "    filtered_counts = get_mutation_sharing_counts(input_df, n_samples)\n",
    "    unfiltered_counts = get_mutation_sharing_counts(unfiltered_input_df, n_samples)\n",
    "    filtered_out_counts = unfiltered_counts - filtered_counts\n",
    "\n",
    "#    plot_mutation_sharing_comparison(filtered_counts, filtered_out_counts, n_samples, split_points[query])\n",
    "#    plt.show()\n",
    "#    continue\n",
    "\n",
    "    if query == 'FAP03_P2':\n",
    "        figsize = (12.5, 6.5)\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs_broken = fig.add_gridspec(2, 1, height_ratios=[1, 1], hspace=0.05)\n",
    "        ax1 = fig.add_subplot(gs_broken[0])\n",
    "        ax2 = fig.add_subplot(gs_broken[1])\n",
    "        plot_broken_axis_mutation_sharing(filtered_counts, filtered_out_counts, n_samples, ax1, ax2, split_points[query])\n",
    "    else:\n",
    "        if query == 'FAP01_T3':\n",
    "            figsize = (11, 6.5)\n",
    "        else:\n",
    "            figsize = (5, 6.5)\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        plot_stacked_mutation_sharing_simple(filtered_counts, filtered_out_counts, n_samples, ax)\n",
    "\n",
    "    if save_plots:\n",
    "        plt.savefig(f'figures/mutation_sharing_{query}.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'FAP03_P2'\n",
    "store = stores[query]\n",
    "query_str = \"~Tumor_Sample_Barcode.str.contains('_N')\"\n",
    "input_df = store.sample_df.query(query_str).copy()\n",
    "samples = input_df.Tumor_Sample_Barcode.unique()\n",
    "unfiltered_input_df = tbl.query('Tumor_Sample_Barcode in @samples').copy()\n",
    "\n",
    "df_filtered = input_df.copy()\n",
    "df_unfiltered = unfiltered_input_df.copy()\n",
    "\n",
    "# Extract region from sample name, e.g., \"FAP03_P2_R4_G7\" -> \"R4\"\n",
    "def extract_region(sample_name):\n",
    "    m = re.search(r'(R\\d+)', sample_name)\n",
    "    return m.group(1) if m else 'Unknown'\n",
    "\n",
    "df_filtered['region'] = df_filtered[store.sample_col].apply(extract_region)\n",
    "df_unfiltered['region'] = df_unfiltered[store.sample_col].apply(extract_region)\n",
    "\n",
    "# Get all regions and order them as R1, R2, ..., Unknown (if present)\n",
    "def region_sort_key(region):\n",
    "    m = re.match(r'R(\\d+)', region)\n",
    "    return (0, int(m.group(1))) if m else (1, region)\n",
    "\n",
    "regions = sorted(df_filtered['region'].unique(), key=region_sort_key)\n",
    "\n",
    "# Map region to color by finding the first sample in that region and using its color from store.colordict\n",
    "region_to_color = {}\n",
    "for region in regions:\n",
    "    region_samples = df_filtered.loc[df_filtered['region'] == region, store.sample_col]\n",
    "    color = \"steelblue\"\n",
    "    for sample in region_samples:\n",
    "        if sample in store.colordict:\n",
    "            color = store.colordict[sample]\n",
    "            break\n",
    "    region_to_color[region] = color\n",
    "\n",
    "# Prepare a DataFrame to collect counts per region\n",
    "all_counts = []\n",
    "\n",
    "for region in regions:\n",
    "    # Get counts for filtered and unfiltered data\n",
    "    df_filtered_region = df_filtered[df_filtered['region'] == region]\n",
    "    df_unfiltered_region = df_unfiltered[df_unfiltered['region'] == region]\n",
    "    \n",
    "    # Calculate per-region n_samples\n",
    "    region_n_samples = df_filtered_region[store.sample_col].nunique()\n",
    "    \n",
    "    region_filtered_counts = get_mutation_sharing_counts(df_filtered_region, region_n_samples)\n",
    "    region_unfiltered_counts = get_mutation_sharing_counts(df_unfiltered_region, region_n_samples)\n",
    "    \n",
    "    # Calculate filtered out counts\n",
    "    region_filtered_out_counts = region_unfiltered_counts - region_filtered_counts\n",
    "    \n",
    "    region_df = pd.DataFrame({\n",
    "        'num_samples': region_filtered_counts.index,\n",
    "        'filtered_count': region_filtered_counts.values,\n",
    "        'filtered_out_count': region_filtered_out_counts.values,\n",
    "        'unfiltered_count': region_unfiltered_counts.values,\n",
    "        'region': region\n",
    "    })\n",
    "    all_counts.append(region_df)\n",
    "\n",
    "plot_df = pd.concat(all_counts, ignore_index=True)\n",
    "\n",
    "# Ensure region column is categorical with the desired order for plotting\n",
    "plot_df['region'] = pd.Categorical(plot_df['region'], categories=regions, ordered=True)\n",
    "\n",
    "# Plot: do NOT share x-axis, so each region can have its own x range\n",
    "def region_stacked_barplot(data, **kwargs):\n",
    "    region = data['region'].iloc[0]\n",
    "    bar_color = region_to_color.get(region, \"steelblue\")\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    x_positions = data['num_samples']\n",
    "    \n",
    "    # Create stacked bars\n",
    "    ax.bar(x_positions, data['filtered_count'], color=bar_color, label=\"Filtered mutations\")\n",
    "    ax.bar(x_positions, data['filtered_out_count'], \n",
    "           bottom=data['filtered_count'], color=\"gray\", label=\"Filtered out mutations\")\n",
    "    \n",
    "    # Ensure x-axis labels are integers\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels([int(x) for x in x_positions])\n",
    "    ax.grid(axis='x', visible=False)\n",
    "\n",
    "g = sns.FacetGrid(plot_df, col=\"region\", col_wrap=3, sharey=False, sharex=False, height=3, aspect=1.2)\n",
    "g.map_dataframe(region_stacked_barplot)\n",
    "g.set_axis_labels(\"Number of samples with mutation\", \"Number of mutations\")\n",
    "g.set_titles(\"Region: {col_name}\")\n",
    "\n",
    "# Add legend to the first subplot in top-right position\n",
    "g.axes[3].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print the actual figure size\n",
    "fig = g.figure\n",
    "figsize_inches = fig.get_size_inches()\n",
    "print(f\"Actual figure size: {figsize_inches[0]:.1f} x {figsize_inches[1]:.1f} inches\")\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(f'figures/mutation_sharing_{query}-regions.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
